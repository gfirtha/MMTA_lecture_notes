The previous chapter introduced the representation of color pixels in analog and digital systems.
The current chapter presents how analog and digital video signals can be formed by using these pixel representations and discusses how the parameters of the resulting video formats were chosen.

\section{Structure and properties of the video signal}

The discussion starts with the questions that arose at the establishment of the early analog TV broadcast systems, beginning with the format parameters elaborated for the NTSC and PAL standards and later adopted by the SD digital format.
These analog systems are, of course, already superseded by digital transmission and broadcasting standards.
However, their discussion is still of great importance, on one hand because the principles of their actual parameter choices hold unchanged for introducing modern systems as well.
On the other hand, a large number of parameters, used in HD and UHD formats are the legacy of these early systems.

\subsection{Structure of the analog video signal}

Before discussing the actual video parameters the structure of the video signals is introduced.
The term video signal refers to the signal, carrying video information either from a broadcasting video source, or between local electronic devices (e.g. from set-top-box to the TV on a HDMI interface, or from a computer/laptop to an external display through VGA interface).
Even today, the structure of the digital video signal is completely identical with the analog representation, that's structure is the result of the operation principle of early CRT displays.

In the previous chapter \ref{sec:CRT} gave a detailed explanation on the principle of cathode-ray tube based imaging devices:
The realization of the RGB primaries was achieved by phosphores covering the screen, emitting visible light when excited.
The excitation was ensured by an electron gun, producing a narrow electron beam, with the current density being approximately proportional to the 2.2 power of the input voltage (hence the original need for gamma correction).

The electron beams (one in case of black and white, three beams in case of colored display), driven with the input voltage of the video signal, are focused and steered by properly driven magnetic coils, and scan the display screen line by line, along \textbf{scan lines} in a predefined \textbf{raster scanning pattern}\footnote{The choice of scanning the screen linewise is not absolutely obvious, while creating the early black and white TV standards other solution, e.g. columnwise or back-and-fortha linewise scanning types were also investigated.}.
As the electron beam reaches the end of a given scan line, it retraces horizontally to the beginning of the next line.
Similarly, by reaching the lower end of the screen the beam retraces vertically to the beginning of the next frame.

An important principle of CRT displays is that the video data is received and displayed real-time, instantaneously (when early TV receivers were introduced circuits existed for storing video data).
Hence, the analog video signal is basically the driving voltage of the CRT electron guns, containing the video data line by line: 
In case of a black and white display, the video signal consists of the continuous luma information $Y'$, while in color receivers the receiver either receives directly the $R'G'B'$ signals (not used in video broadcasting), or demodulates them from the luma-chroma representation.
The principle of raster scanning is depicted in Figure \ref{Fig:TV_signal} (a).
%
\begin{figure}[]
	\centering
	\begin{minipage}[c]{0.3\textwidth}
		\begin{overpic}[width = 1\columnwidth ]{figures/FormatJargon-1.png}	
		\small
		\put(0,0){(a)}		
		\end{overpic}
				\begin{overpic}[width = 1\columnwidth ]{figures/TV.png}	
		\small
		\put(0,0){(d)}		
		\end{overpic}
	\end{minipage} \hfill
	\begin{minipage}[c]{0.68\textwidth}
		\centering
		\begin{overpic}[width = 0.86\columnwidth ]{figures/FormatJargon-3.png}		\small
		\put(0,0){(b)}		\end{overpic}
		\begin{overpic}[width = 1\columnwidth ]{figures/FormatJargon-7.png}		\small
		\put(0,0){(c)}		\end{overpic}
	\end{minipage}
%
	\caption{General structure of analog video signal}
	\label{Fig:TV_signal}
\end{figure}
%

Obviously, it takes a finite time for the electron beam to retrace from the end of a line to the beginning of the next one, and similarly to retrace from the end of the screen to the beginning.
During these \textbf{retracing intervals} the electron beam is turned off, i.e. \textbf{blanked}, otherwise undesired traces would appear on the screen.
In practice this means that during these \textbf{blanking intervals} the video signal is zero, or negative valued, i.e. it takes black level, or synch level.
In the blanking interval synchronizing pulses are added to the video signal that ensure that the oscillators in the receiver remain locked with the transmitted signal, so that the image can be reconstructed on the receiver screen.

Based on the foregoing the linewise video signal contains three distinct time intervals:
\begin{itemize}
\item The \textbf{active video content}, containing the actual video information of one line.
In analog formats the length of the active video interval is expressed in $\mu \mathrm{s}$, and in $\mathrm{px}$-s in the digital case.
\item The \textbf{horizontal blanking interval}, the time it takes for the electron beam to retrace from the end of the actual scan line to the beginning of the next scan line.
The horizontal blanking interval contains the horizontal sync pulse (\textbf{HSYNC}) with negative signal level (i.e. ,,blacker than black''), serving as the trigger pulse for the horizontal retracing circuit.
The sync pulse is separated from the active video data with black level intervals before and after the sync pulse, termed as the front porch and black porch.
The length of horizontal blanking is expressed in $\mu \mathrm{s}$ in the analog, and in $\mathrm{px}$-s in the digital case.
\item The \textbf{vertical blanking interval (VBI)}, the time it takes for the electron beam to retrace from the end of the actual frame to the beginning of the next frame.
The vertical blanking interval contains the vertical sync pulses (\textbf{VSYNC}) at negative signal level, allowing the vertical synchronization of the display frames on the screen.
The length of the VBI is expressed in lines (number of the inactive lines).
\end{itemize}
The video signal, therefore, contains in one entire line period time ($T_{\mathrm{H}}$, for horizontal) both \textbf{active video interval} and \textbf{inactive interval}, carrying no video information.
The structure of video lines is depicted in Figure \ref{Fig:TV_signal} (b).
Similarly, the entire period time of one frame ($T_{\mathrm{V}}$, as vertical) contains \textbf{active lines} and \textbf{inactive lines}, containing no actual video data.
The structure of active and inactive lines is depicted in Figure \ref{Fig:TV_signal} (c).

In the following it is revealed what principles lead to the actual timing parameters (e.g. the lengths of the above intervals, line frequency, frame frequency) and to the standard definition resolution parameters. 

\subsection{Parameters of analog video formats}

\subsubsection*{Aspect ratio and display size}

First it is explained what display size should be the optimal format parameters chosen for.

It was already discussed in \ref{Sev:HVS} that the human color vision is ensured by the macula, containing mostly cones, located around the center of the retina.
In the center of the macula the fovea is responsible for sharp central vision (also called foveal vision).
Due to the size of the fovea, the human central vision with high visual acuity covers about $10-15^{\circ}$ from the entire field of view of $\approx 200^{\circ}$ horizontally.
During the creation of standard definition television standard the basic goal was to fill only the central vision with content, therefore, the SD television should cover about $10^{\circ}$ from the horizontal field of view (i.e. the peripheral vision does not contribute to imaging).
Obviously, the actual display size then depends on the viewing distance, as it will be discussed later in this chapter.

\vspace{3mm}
Another important spatial attribute of video formats is the ratio of the horizontal and vertical screen size, i.e. the \textbf{aspect ratio} ($a_r$).
The basis of all the color TV formats was the NTSC standard and its black and white predecessor, introduced in the 1940s.
As an obvious endeavor the introduced broadcasting format was engineered in order to be compatible with the then-existing video sources, e.g. movie films.
Until the 1950s during the entire silent film era movies were almost exclusively captured with the aspect ratio of 4:3, i.e. the ratio of the horizontal and vertical screen size was $1.3\dot{3}$
\footnote{
The introduction of the aspect ratio of 4:3 is connected to the work of Thomas Alva Edison, who \href{https://en.wikipedia.org/wiki/35_mm_movie_film}{defined} the standard image exposure length on $35~\mathrm{mm}$ film for movies is four perforations ($19~\mathrm{mm}$) per frame along both edges. 
From the available film width between perforations ($25.375~\mathrm{mm}$) the active are has an aspect ratio of 4:3.
This \href{https://en.wikipedia.org/wiki/Negative_pulldown}{4-perf negative pulldown} became the official standard in 1909, allowing the emerging of standard movie cameras, movie projectors, and hence emerging of cinema technologies.}.
Although by the 1950s first widescreen movie formats have already emerged, the NTSC standard adopted the \textbf{4:3} aspect ratio, which remained the standard TV and video aspect ratio until the introduction of the HD format.

%TODO anamorphic lenses?
% Forr√°s: https://www.shutterstock.com/blog/4-3-aspect-ratio
% https://www.cinematographers.nl/FORMATS1.html

\subsubsection*{Refresh rate and frame rate}

The next parameter to investigate is the temporal sampling frequency of the video data, i.e. the number of frame fed to the display device per second.
First three closely related terms are introduced:
\begin{itemize}
\item The \textbf{refresh rate} ($\mathbf{f_{\mathrm{r}}}$) refers to the number of times in a second that a display ,,flashes'', i.e. redraws its content, expressed usually in $\mathrm{Hz}$.
\item The \textbf{frame rate} ($\mathbf{f_{\mathrm{V}}}$) express the number of time in a second that the content of the display changes, i.e. the number of frames, contained by the video signal per second, usually expressed in $\mathrm{fps}$ (frame per second) or in $\mathrm{Hz}$.
\item The \textbf{field rate} ($\mathbf{f_{\frac{\mathrm{V}}{2}}}$) can be defined for interlaced video data, denoting the number of fields (half frames) per second in the video data, generally expressed in $\mathrm{fps}$.
Universally $f_{\frac{\mathrm{V}}{2}} = 2\cdot f_{\mathrm{V}}$ holds.
\end{itemize}
The key difference between refresh rate and frame rate is that refresh rate is the property of the display device (e.g. LCD display) and includes the repeated drawing of identical frames, while frame rate measures how often a video source can feed an entire frame of new data to a display.

In order to arrive at practical frame rate and refresh rate choice for video data two perceptual aspects have to be taken into consideration:
\begin{itemize}
\item On one hand when reproducing objects under motion it is crucial to display sufficient number of motion phases in order to ensure that the observer perceives a smooth, continuous motion.
This requirement constitutes a lower limit for the applicable frame rate.
\item On the other hand the refresh rate has to be chosen high enough in order to avoid \textbf{flickering} and to reduce eye strain.
\end{itemize}
Due to the \textbf{beta movement} phenomenon the frame rate can be significantly lower, than the refresh rate:
Beta movement is an optical illusion whereby viewing a rapidly changing series of static images creates the illusion of a smoothly flowing scene, occurring if the frame rate is greater than 10 to 12 $\mathrm{fps}$. 
Therefore, due to the beta movement the frame rate should satisfy
\begin{equation}
f_{\mathrm{frame}} > \sim20~\mathrm{Hz},
\end{equation}
\footnote{
It is worth noting that the above frame rate only allows the perception of motion instead of distinct static images, higher frame rates )(usually $60~\mathrm{fps}$) still ensure much smoother motion reproduction.
In order to increase the effective frame rate of the video stream, modern displays and software allow temporal interpolation by estimating the intermediate frames, based on some motion prediction algorithm, similarly to MPEG encoding.
However, the average viewer already adapted to the frame rate of $24~\mathrm{fps}$, being the standard frame rate of movie films, therefore the increased frame rate often generates an unpleasant, unnatural effect.
This is termed as the \textbf{soap opera effect}, originating from the fact that usually low cost TV shows are recorded directly to digital video cameras (being much cheaper than capturing to film), allowing higher frame rates, usually set to $60 \mathrm{fps}$.}
however, applying the same refresh rate would lead to serious perceived flickering artifacts.

In over to avoid flickering the refresh rate has to be higher than the \textbf{flicker fusion threshold}
\footnote{
The flickering fusion threshold is the frequency at which an intermittent light stimulus appears to be completely steady to the average human observer.
For surfaces with temporally alternating luminances above the flickering threshold the average luminance is perceived.
The threshold depends on numerous factors:
Depends on the average illumination intensity, the adaptation state, the color of vibration (above $15-20~\mathrm{Hz}$ fluctuation of hue information can not be perceived) of and the position on the retina at which the stimulation occurs}.
For the purposes of presenting moving images, the human flicker fusion threshold is usually taken between 60 and $90~\mathrm{Hz}$:
in the central vision, dominated by the cones the response time is high, and the flickering fusion threshold is around $50~\mathrm{Hz}$.
The peripheral vision is dominated by the rods, with a much lower response time and the flickering fusion threshold is higher.

In case of analog TV formats the goal was to fill the central vision of the viewer with, therefore, with a refresh rate of
\begin{equation}
f_{\mathrm{r}} > 50-60~\mathrm{Hz} 
\end{equation}
flickering can be avoided\footnote{This is true only for the central vision.
The flickering of CRTs can be easily observed with a display watched from the peripheral vision}.
The choice of the actual refresh rate was, however, a consequence of the CRT technology's imperfection: a trick in order to avoid the effect of the supply voltage ripple.

\begin{figure}[]
	\centering
	\begin{overpic}[width = 1\columnwidth ]{figures/ripple.png}
	\end{overpic}
	\caption{Source of the supply voltage ripple in a single-way rectifier}
	\label{Fig:ripple}
\end{figure}

\paragraph*{Effect of the mains frequency:}
Voltage ripple is the residual periodic variation of the DC voltage in a power supply due to the imperfect rectification of the alternating means AC voltage, as illustrated in \ref{Fig:ripple}.
The ripple frequency coincides with the means frequency in case of single-way rectification, or with its double in the two-way case.
As in a CRT display the anode is directly connected to the supply voltage, therefore, any perturbation in the DC voltage is directly added to the video signal and is displayed on the screen.

Assume a screen consisting of $N_{\mathrm{V}}$ horizontal scan lines, with the refresh rate denoted by $f_\mathrm{r}$.
The number of scan lines displayed in a second, i.e. the line frequency is given by
\begin{equation}
f_\mathrm{H} = N_\mathrm{V} \cdot f_\mathrm{r}.
\end{equation}
In order to investigate the effect of supply ripple, as a generalization, assume a periodic black and white video signal, oscillating between 0 and 1, described by
\begin{equation}
Y(t) = \frac{1}{2} \left( 1 + \sin 2 \pi f t \right),
\end{equation}
with $f$ being the signal frequency. 
For the sake of simplicity the blanking intervals are assumed to be of zero length.
In this case the sine wave is displayed on the screen line by line.
Depending on the signal frequency $f$ the content of the screen can be the following:
\begin{itemize}
\item If $f = f_\mathrm{H}$ each scan line consists of exactly one period of the sine wave, resulting in a horizontal sine on the screen, as depicted in Figure \ref{Fig:ripple_display} (a).
\item If $f > f_\mathrm{H}$ each scan line consists of less then one period of the sine wave, with the initial phase in the beginning of the scan lines increasing line by line and frame by frame.
Therefore, the horizontal sine on the screen is slightly steered, and moves towards left.
Similarly, with $f < f_\mathrm{H}$ the image moves slowly towards right.
\item If $f = f_\mathrm{r}$ each frame consists of a single period of the sine wave.
Assuming $N_\mathrm{V} \gg 1$ the value of the sine function changes insignificantly over one scan line, therefore, the displayed image is a vertical sine.
\item If $f > f_\mathrm{r}$ the initial phase of the vertical sine increases frame by frame, thus, the sine wave moves slowly upwards.
Similarly, for $f < f_\mathrm{r}$ the vertical sine moves downwards.
%
\end{itemize}
\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.45\columnwidth ]{figures/horizontal_sine.png}
	\small
	\put(0,0){(a)}
	\end{overpic}
	\hspace{5mm}
	\begin{overpic}[width = 0.45\columnwidth ]{figures/vertical_sine.png}
	\small
	\put(0,0){(b)}
	\end{overpic}
	\caption{Periodic video signal with $f = f_\mathrm{H}$ (a) and $f = f_V$ (b) as displayed line by line}
	\label{Fig:ripple_display}
\end{figure}
%
Based on the foregoing, with the appropriate synchronization of the signal frequency and the refresh rate a periodic video signal can be displayed as a still, non-moving image.
The effect of voltage ripple acts as such a periodic noise signal, with the frequency determined by the mains voltage of the given region and displayed inevitably on the screen.
Early tests with black and white TV receiver suggested the visible effect of this periodic noise of less disturbing if the noise image is still.
Therefore, both in the American, and later in the European systems refresh rate was chosen to coincide the mains frequency
\footnote{
In the American NTSC system with the introduction of color information the choice of refresh rate became more complicated, as the frequency of the color subcarrier could not be correctly chosen.
Without more details: as a consequence both the refresh rate (and the field rate) and the line frequency had to be decreased by $0.1~\%$.
Therefore, in the American system the refresh rate is $f_r = 60\cdot \frac{1000}{1001} = 59.94~\mathrm{Hz}$.
Due to the presence of vertical and horizontal sync pulses, this change did not had and effect on the then-existing TV receivers.}.
\begin{equation}
f_{\mathrm{r,USA}} = 60~\mathrm{Hz}, \hspace{1cm} f_{\mathrm{r,Eu}} = 50~\mathrm{Hz}
\end{equation}
ensuring that supply ripple only manifests in a non-moving vertical noise image on the screen.

Having found the refresh rate for early TV systems, which has been also in use by modern CRTs and LCD displays, still, the actual frame rate is an open question.
An obvious choice for the frame rate would be the refresh rate itself.
Due to bandwidth efficiency, however, instead a special raster scan order was introduced. 

\subsubsection*{Raster scan orders}

The raster scan order is the rectangular pattern of image capture and reconstruction in television.
In the receiver side it defines the systematic process how the electron beam scans the entire screen over a given time interval.
The following section introduces two frequently used raster scan order, leading to the definition of frame rate and field rate for.

Obviously, for currently used LCD and OLED displays the raster scan order can not be interpreted as the scanning pattern of the display, since the entire display content is updated in the same time instant.
Still, scan order can be understood also as the storing and transmission order of video data, hence scan order is interpretable in modern video systems as well.

\paragraph{Progressive scan:}
As the most straightforward scanning order, \textbf{progressive scan} is a format of displaying, storing, or transmitting moving images in which all the lines of each frame are drawn in sequence.
In the receiver side it means that the electron beam scans and updates the content of the entire screen over one frame time ($T_{\mathrm{V}} = 1/f_{\mathrm{V}}$), line by line.
\begin{figure}[]
	\centering
	\begin{minipage}[c]{0.6\textwidth}
	\begin{overpic}[width = 1\columnwidth ]{Figures/progressive_scan.png}
	\end{overpic}   \end{minipage}\hfill
		\begin{minipage}[c]{0.3\textwidth}
	\caption{Illustration of progressive scanning (for the sake of simplicity with the exemplary number of 11 lines), with the active line content (1), the vertical retrace/blanking interval (2) and the horizontal retrace/blanking interval (3).}
	\label{Fig:progressive}  \end{minipage}
\end{figure}
Progressive scanning is illustrated in Figure \ref{Fig:progressive}.

In the aspect of transmission in case of video data with progressive scanning the content of the entire frames has to be transmitted over the frame time via the given interface (e.g. HDMI) sequentially.
Progressive scan is usually denoted by letter ,,p'' in the format designation.

Although progressive scan seems to be the most simple and obvious scan order, still, until the emergence of the UHD format progressive scan was only occasionally utilized due to the reasons discussed in the following.

\vspace{3mm}
\paragraph{Interlaced scan:}
The previous section have already discussed that in order to avoid flickering the display refresh rate should be risen above $50~\mathrm{Hz}$, while for ensuring continuous motion the video frame rate of around $20~\mathrm{Hz}$ may be sufficient.
This fact suggests that frame rate should be handled independently by choosing a high refresh rate and a efficiently low frame rate, allowing the reduction of video data and the required bandwith for transmission.

This concept could be easily implemented in cinematic techniques:
As a heritage of the early silent movie era (where the frame rate varied between $16-24~\mathrm{Hz}$) movie films are commonly captured with the frame rate of 24 frames per second.
In order to avoid flickering the film projectors are equipped with special \href{https://www.youtube.com/watch?v=jrSzRAch930}{two or three blade shutters}, rotating in front of the projector beam and flashing each frame two or three times before the film would travel to the next frame.
With the simple trick of presenting the same frame multiple times the effective refresh rate can be increased to $48\mathrm{fps}$ or $72~\mathrm{fps}$, and flickering may be avoided.

Also, nowadays frame rate and refresh rate can be handled independently in digital systems (e.g. in a video card and a VGA monitor), where a \textbf{display buffer} is present, containing the data of an entire frame, generating and feeding the video signals towards the display.
Modern LCD displays are usually built with the LED backlight panel flashing at around $200~\mathrm{Hz}$\footnote{
Obviously, the LED panel could be built with continuous driving voltage of well, instead of flashing, but the dynamic adjustment of its lightness (based on the video content) can be much cost-efficiently solved with PWM modulation.}.
Still, as a rule of thumb even in the presence of a video buffer the content of the video buffer may change during the vertical blanking of the display in order to avoid \href{https://en.wikipedia.org/wiki/Screen_tearing#/media/File:Tearing_(simulated).jpg}{screen tearing}.
As a consequence, generally $f_{\mathrm{r}} = \mathrm{n} \cdot f_{\mathrm{V}}$ holds, where $\mathrm{n} \in \lbrace 1,2,3,... \rbrace$.

In analog TV receiver no frame buffer could be present due to the lack of appropriate technology, the transmitted signal had to be displayed by the receiver on the fly.
Obviously, transmitting the same frames multiple times requires a significant increase of bandwidth. 
Therefore, a more simple engineering workaround was needed for the bandwidth efficient video transmission, which was eventually provided by the concept of \textbf{interlace scanning}.

\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.85 \columnwidth ]{Figures/interlaced_scan.png}
	\end{overpic}
	\caption{Illustration of interlaced scanning (for the sake of simplicity with the exemplary number of 21 lines)
	Assuming that scanning starts with the beginning of the first scan line, in order to cover the entire screen the first field has to end in a half-line, and the second field has to start with a half-line.
	This requirement can be satisfied only by applying odd number of scan lines (each field consists of $N_{\frac{V}{2}} + \frac{1}{2}$ lines, thus the total line number is given by $2 N_{\frac{V}{2}} + 1$, being an odd number by definition). }
	\label{Fig:interlaced}
\end{figure}

The basic concept of interlaced scanning is illustrated in Figure \ref{Fig:interlaced}:
Instead of scanning each line of the display within one frame period time, the screen is divided into two \textbf{fields}
\begin{itemize}
\item the \textbf{odd field}, containing every odd scan line 
\item the \textbf{even field}, containing every even scan numbered scan line
\end{itemize}
The interlaced signal contains the two fields of a video frame captured consecutively (i.e. the even and odd fields are captured in consequent time instants).
Similarly, in the receiver the electron beam scans first all the odd lines, displaying the content of the odd field, then draws the content of the even field into all the even lines.
Interlaced scan is usually denoted by letter ,,i'' in the format designation.

By applying interlaced scanning the content of the display is redrawn with the frequency of the fields, thus, for interlaced video the refresh rate is given by the \textbf{field rate} ($f_{\frac{\mathrm{V}}{2}}$).
Therefore, the field rate is determined by the mains frequency of the given region, being $50~\mathrm{Hz}$ for the European and $60~\mathrm{Hz}$ (more precisely $59.94~\mathrm{Hz}$) for the American electric network.
Furthermore, the period time of an entire frame, consisting both even and odd fields is obviously twice the field period time, thus the frame rate is half of the field rate.
As a result in the frame rate is $25~\mathrm{Hz}$ in the European and $30~\mathrm{Hz}$ ($29.97~\mathrm{Hz}$) in the American systems, being high enough to ensure the perception of continuous motion, while the refresh rate is sufficient in order to avoid flickering.
As a summary for the foregoing in the European and American system 
\begin{align}
\begin{split}
f_{\mathrm{r,USA}} &= f_{\frac{\mathrm{V}}{2},\mathrm{USA}} = 2\cdot f_{\mathrm{V},\mathrm{USA}} = 60~\mathrm{Hz} , \hspace{1cm}  f_{\mathrm{V},\mathrm{USA}}= 30~\mathrm{Hz} \\
f_{\mathrm{r,Eu}} &= f_{\frac{\mathrm{V}}{2},\mathrm{Eu}} =  2\cdot f_{\mathrm{V},\mathrm{Eu}} = 50~\mathrm{Hz}, \hspace{1cm}  f_{\mathrm{V},\mathrm{Eu}}= 25~\mathrm{Hz}
\end{split}
\end{align}
hold.

Opposed to the solution of cinema, i.e. displaying the same frame multiple times the even and odd fields in interlaced video are taken in consequent time instants.
Therefore, in interlaced video the temporal resolution is effectively doubled at the cost of halving the vertical spatial resolution of the video data.
This means the following properties of interlaced video
\begin{itemize}
\item Compared to progressive video with the same refresh rate, interlaced scanning achieves the compression factor of 2:1, resulting in halved analog bandwidth
\item In case of still, and slowly moving scenes the vertical resolution coincides with the progressive resolution (since the even and odd fields complete the same frame)
\item In case of rapid motion the vertical resolution if half of the progressive resolution
\end{itemize}
Generally speaking for video content with slowly changing content, e.g. movies, interlaced scanning ensures a sufficiently high vertical resolution with improved motion reproduction besides feasible signal bandwidth.
In case of fast motion, e.g. camera movements in sport programs the artifacts due to the reduced vertical resolution become visible.
\vspace{3mm}

As bandwidth efficiency was of primary importance during the introduction of early analog television broadcasting, all the analog and digital standard definition video formats adopted exclusively interlaced scanning.
Later the high definition video standard introduced progressive video formats for the first time, while the latest ultra high definition format supports progressive scanning mode only.

\vspace{3mm}
\paragraph{Questions of interlaced scanning:}
Besides its obvious advantages, the application of interlaced video rises a number of questions and challenges.

As an example, it introduces the phenomenon of \textbf{interline twitter}:
The previous chapter explained that the violation of the sampling theorem---i.e. sampling frequency components above half the sampling frequency---leads to spatial aliasing phenomena.
In the field of image processing it manifests in visible Moir√© pattern on spatially periodic textures (e.g. a brick wall, or squared shirts).
In case of interlaced video the vertical resolution is halved, compared to progressing scanning, therefore, vertical aliasing artifacts are more likely to emerge.
Since the even and odd fields are displayed alternatively, therefore also the potential Moir√© patterns alternate from field to field.
This may produce a shimmering effect, termed as twittering, even when a still image is \href{https://en.wikipedia.org/wiki/File:Indian_Head_interlace.gif}{reproduced}.
Interline twittering is the main reason, why television professionals avoid wearing clothing with fine striped patterns, while professional video cameras apply a low-pass filter to the vertical resolution of the signal to prevent interline twitter. 

\begin{figure}  
\small
  \begin{minipage}[c]{0.64\textwidth}
	\begin{overpic}[width = 1\columnwidth ]{Figures/Interlaced_video_frame_(car_wheel).jpg}
	\end{overpic}   \end{minipage}\hfill
	\begin{minipage}[c]{0.3\textwidth}
    \caption{
    Displaying interlaced video on a progressive display without deinterlacing.}
\label{fig:deinterlacing}  \end{minipage}
\end{figure}

Further questions arise in case of the conversion between interlaced and progressive formats.
The progressive to interlaced conversion can be straightforwardly solved by dividing the entire frame to odd and even lines.
Interlaced to progressive conversion emerges more frequently in practice: e.g. in case of the playback of a DVD disc on a usually progressive computer monitor.
As the simplest solution, two adjacent field can be combined to form a single frame, however, this naive approach leads to the ,,combing'' of moving objects on the screen, as illustrated in Figure \ref{fig:deinterlacing}.
Generally speaking techniques for the interpolation of the content of intermediate scan lines are termed as \textbf{deinterlacing} methods.
Deinterlacing is an often emerging problem even today, as broadcasting most often transmits interlaced HD format (generally using format 1080i), while modern LCD displays do not support native interlaced scanning anymore.


\section{Analog video formats}

\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.8\columnwidth ]{figures_en/NTSC_PAL.png}
	\end{overpic}
	\caption{Distribution of analog television formats by nation}
	\label{Fig:NTSC_map}
\end{figure}

Based on the foregoing, the main properties of the video format used for analog broadcasting can be introduced.
Historically, three analog video formats were introduced with the advent of color television broadcasting:
\begin{itemize}
\item The first color TV broadcast system was the \textbf{NTSC} format, introduced by the Federal Communications Commission (FCC) in the United States in 1954 and have been adopted by western America and Japan.
For vertical resolution NTSC selected $N_V = 525$ scan lines\footnote{
The choice of the vertical line number was a compromise between the existing black and white systems, e.g. as used by RCA's NBC TV network, and the intention of manufactures, desiring to increase the line number to 600-800.
The actual value originates from a limitation of the CRT technology of the day:
In early TV receivers a master oscillator ran at twice the line-frequency, and this frequency ($2\cdot 15750~\mathrm{Hz}$) was divided down by the number of lines used (in this case $N_V = 525$) to give the field frequency ($f_{\frac{\mathrm{V}}{2}} = 60~\mathrm{Hz}$).
This frequency was compared with the mains frequency ($60~\mathrm{Hz}$ in America) and the master oscillator's frequency was corrected by the discrepancy in order to avoid a moving noise image due to supply ripple.
At the time, frequency division was performed use of a chain of multivibrators, the overall division ratio being the mathematical product of the division ratios of the chain.
Since the line number has to be odd an odd number (see previous section), therefore it can be factorized only to odd numbers as well, which had do be relatively small in order to avoid thermal drift of the oscillator.
The closest sequence up to about 500 lines that meets all these requirements is $525 = 3\cdot 5\cdot 5 \cdot 7$, giving the number of scan lines.}
with interlaced scanning and the	 field rate of $f_{\mathrm{\frac{V}{2}}} = 60~\mathrm{Hz}$ in agreement with the mains frequency.
\item As an improved version of NTSC, the \textbf{PAL} system was introduced by the European Broadcasting Union (EBU) in 1967 and besides Europe it was adopted in Australia, South America, Africa and a part of Asia.
The PAL format applied interlaced scanning with the number of scan lines of $N_V = 625$ along with the field rate of $50~\mathrm{Hz}$.
\item Also as an improvement on NTSC, emerging from France the \textbf{SECAM} system was introduced in France and in the Soviet Union.
The SECAM system will not be discussed in details in the present book.
\end{itemize}
The main parameters of the NTSC and PAL formats are summarized in Table \ref{tab:sd_formats}.
As a summary it can be stated that NTSC provides a higher temporal resolution (i.e. higher refresh rate/field rate) with lower spatial resolution, while PAL ensures a higher spatial resolution due to the increased number of scan lines at the cost of lower field rate.

\begin{table}[h!]
\caption{Parameters of the NTSC and PAL analog formats}
\renewcommand*{\arraystretch}{2.25}
\label{tab:sd_formats}
\begin{center}
    \begin{tabular}[h!]{ @{}c | | l | l @{} }%\toprule
				         &   NTSC  							       & PAL \\ \hline
    Total line number ($N_{\mathrm{V}}$):	 &  525   								   &  625 \\
    Number of active lines ($N_{\mathrm{V,A}}$):   &  480   								   &  576 \\
    Frame rate ($f_{\mathrm{V}}$):    &  $30~\mathrm{Hz}$ ($29.97~\mathrm{Hz}$) & $25~\mathrm{Hz}$ \\
    Field rate ($f_{\frac{\mathrm{V}}{2}}$): &  $60~\mathrm{Hz}$ ($59.94~\mathrm{Hz}$) & $30~\mathrm{Hz}$ \\
    Line frequency ($f_{\mathrm{H}}$):    &  $525 \cdot 30 = 15750~\mathrm{Hz}$ ($15734~\mathrm{Hz}$) & $15625~\mathrm{Hz}$ \\
    Line period time ($T_{\mathrm{H}}$):           &  $63.49~\mathrm{\mu s}$ ($63.55~\mathrm{\mu s}$) & $64~\mathrm{\mu s}$ \\
    Active line time ($T_{\mathrm{H,a}}$):           &  $\approx 52 ~\mathrm{\mu s}$ ($63.55~\mathrm{\mu s}$) & $52~\mathrm{\mu s}$ \\
    \end{tabular}
\end{center}
\end{table}

\begin{figure}[t!]
\captionsetup{singlelinecheck=off}
\small
  \begin{minipage}[c]{0.64\textwidth}
	\begin{overpic}[width = 1\columnwidth ]{Figures/Timing_PAL_FrameSignal.png}
	\end{overpic}
    \end{minipage} \hfill
	  \begin{minipage}[c]{0.3\textwidth}
    \caption[]{ The line structure of an entire frame in case of interlaced scan, illustrated for a single video component:
    \begin{itemize}
    \item active line interval: grey
    \item horizontal blanking interval: magenta, cyan and yellow
	\item vertical blanking interval: green, orange and white
    \end{itemize}
    }\label{fig:PAL_frame}
    \end{minipage}
\end{figure}
The structure of an entire frame (i.e. two consecutive fields) in the PAL system is illustrated in Figure \ref{fig:PAL_frame}.
Obviously, the figure depicts only a single video component, the content of the components is discussed in the following.
The figure depicts the horizontal and vertical blanking intervals, with the VSYNC (denoted by green color) and the HSYNC (yellow interval) sync pulses.
These pulses ensure the synchronization of the display to the received signal by triggering the vertical and horizontal retrace of the electron beam, therefore, it is ensured that the individual ,,pixel'' values are displayed on the correct position.
With the loss of these sync pulses the displayed image is misaligned vertically (in case of lost VSYNC), resulting in the \textbf{jitter} or horizontally (in case of lost HSYNC) causing the \textbf{rolling} of the video signal.

Although the characteristics of the video signal---with containing vertical and horizontal blanking intervals---originates from the operation principle of CRT displays, even in modern digital systems (e.g. in case of HDMI or SDI interfaces) the structure of the video signal is identical with the presented analog one.
Obviously, modern LCD displays do not need the presence of blanking intervals at all, since they update the content of all the pixels quasi-instantaneously, still, the blanking intervals are present in digital video signals as well.
One reason for this is that digital video signal is the legacy of the CRT era (and even today, professional CRT studio monitors are often employed), with the newly introduced standards all based on the previous ones.
On the other hand the blanking intervals allow the transmission of auxiliary data, including teletext, captions, subtitles, and in case of digital standards, \textbf{audio streams} of the media content as well.
The actual location of the digital data is codified in ITU-R BT.1364 and SMPTE 291M.
As and example, the audio streams accompanying video data are positioned in the vertical blanking intervals in the HDMI standards, i.e. between the content of active lines
\footnote{
As a simple example for audio transmission via HDMI interface:
In case of a HD format of 1080p (with the total number of lines 1125), with the frame rate of $60~\mathrm{Hz}$, the line frequency is given by $f_V = 67.5~\mathrm{kHz}$.
Assuming an audio stream with 8 channels, sampled at $f_s = 192~\mathrm{kHz}$ the data to be transmitted over one entire frame is $\frac{8 \cdot 192 000 }{60} = 25600~\mathrm{samples}$.
This means the transmission of 23 samples transmitted with one video line, which results in the maximum bandwidth of the HDMI 1.0 \href{https://www.sciencedirect.com/science/article/pii/B9780128016305000049}{standard}.}.

\vspace{3mm}
% https://www.sciencedirect.com/topics/computer-science/blanking-interval
% https://www.sciencedirect.com/topics/computer-science/horizontal-blanking
So far only the general structure of the video signals was discussed, without the investigation of the actual data in the active intervals, e.g. in case of analog video, without investigating what the actual video signals are.
Obviously, the representation of one color pixel requires the transmission of three individual video components, which in the field of video transmission is most often the luma-chroma representation.

Based on the number of actual individual transmitted components video signals can be categorized to two main formats 
\begin{itemize}
\item \textbf{Component video} transmits the video signal on three individual signal paths, i.e. on three individual cable pairs.
\item \textbf{Composite video} transmits the three video signals multiplexed into one single signal, transmitted over a single path, or physically speaking on one pair of cables.
\end{itemize}
\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.90\columnwidth ]{figures/video_comp2.png}
	\end{overpic}
	\caption{Block diagram of the production of composite and component video signals}
	\label{Fig:video_components}
\end{figure}
The signal processing scheme of composite and component video is illustrated in Figure \ref{Fig:video_components}.
As it is depicted, in both cases the basis of video representation is given by the luma-chroma separation of the RGB signals\footnote{Although in case of component video the direct transmission of RGB signals is also allowed in case of UHD video.}.
In the following the actual steps of this production chain is investigated.

\vspace{3mm}
\paragraph{Bandwidth of the video signals:}
Obviously, both the luma and chroma signals are transmitted with finite bandwidth.

As has been already discussed, in case of CRT displays the time domain video signal is drawn on the screen real-time, therefore, the bandwidth of the video signal (defined in $\mathrm{Hz}$) limits the actual horizontal detailedness of the displayed on image.
Thus, the decrease of temporal bandwidth results in the reduction of the spatial, horizontal resolution.
Besides bandwidth efficiency at transmission, the actual choice of video bandwidth has a direct, practical reasons.

The screen of the CRT display is divided both horizontally and vertically to individual RGB pixels.
Therefore, even in case of an continuous CRT driving voltage, the screen itself samples the video signals, that may lead to spatial aliasing artifacts, manifesting in visible Moir√© patterns on the screen.
In order to avoid aliasing the video signal has to be temporally bandlimited \textbf{at least} to the half of the spatial sampling frequency, in accordance with the sampling theorem.

The required temporal bandwidth is investigated for the case of the NTSC format:
From table \ref{tab:sd_formats} the number of active lines in the format is $N_{V,A} = 480$, while the active line time is $t_{H,A} \approx 52~\mu \mathrm{s}$.
As the aspect ratio is 4:3 the number of horizontal pixels is approximately $N_{H,A} = \frac{4}{3} N_{V,A} = 640$ (assuming square pixels).
According to the sampling theorem the sine signal with the largest spatial frequency that can be represented with this resolution contains $N_{H,A}$ periods in one line (this is the consecutive ,,black-white-black-white...'' content).
The period time and the frequency of this signal can be calculated as
\begin{equation}
T_{\mathrm{max}} = \frac{t_H}{N_{H,A}/2}, \hspace{1cm} f_{\mathrm{max}} = \frac{N_{H,A}}{2 t_H} = 6.15~\mathrm{MHz}
\end{equation}
which is the theoretical upper frequency limit, based on the Nyquist criterion.

However, experimental results showed that even this theoretical maximal frequency can not be displayed without artifacts, due to the \textbf{Kell effect}.
The Kell effect is caused by the finite size of the CRT's electron beam: instead of the theoretical infinitely narrow beam, which is assumed when applying the sampling theorem, the electron beam has a \textbf{point spread function (PSF)} (i.e. the intensity profile, when projected to a single point on the screen) described approximately by a Gaussian distribution.
\begin{figure}[]
	\centering
	\begin{minipage}[c]{0.65\textwidth}
	\begin{overpic}[width = 0.95\columnwidth ]{figures/kell.png}
	\end{overpic} \end{minipage}\hfill
	\begin{minipage}[c]{0.35\textwidth}	\caption{Illustration of the Kell effect.}
	\label{Fig:Kell}  \end{minipage}
\end{figure}

A simple example is illustrated in Figure \ref{Fig:Kell} for the effect of the beam PSF:
The continuous image to be displayed oscillates vertically at the Nyquist frequency, with alternating black and white lines.
In case the lines of the image exactly coincides with the sampled lines on the screen (i.e. they are aligned) the image can be reconstructed perfectly.
However, if the lines of the image are located between two actual scan lines, due to the non-zero extension of the electron beam PSF the CRT will display the average of the two lines, i.e. a homogeneous grey image is displayed.

As a conclusion, the theoretical maximal spatial frequency can not be displayed on the screen without artifact.
The ratio of the experimental, subjective highest displayable spatial frequency and the theoretical limit is given by the \textbf{Kell factor}, being approximately 0.7 for the NTSC video parameters.

In order to avoid spatial aliasing and by taking the Kell effect into consideration the largest horizontal frequency that can be displayed on the screen without visible artifacts is given by
\begin{equation}
f^{\mathrm{NTSC}}_{\mathrm{max}} = \frac{N_{H,A} \cdot K}{2 t_H} = 4.3~\mathrm{MHz},
\hspace{3mm}
f^{\mathrm{PAL}}_{\mathrm{max}} = \frac{N_{H,A} \cdot K}{2 t_H} \approx 5.2 ~\mathrm{MHz}
\end{equation}
in the NTSC and PAL systems respectively, where the Kell factor is $K = 0.7$.
Therfore, the luma signal (similarly to the early black and white TV signal) is bandlimited to $4.2~\mathrm{MHz}$ in the NTSC and to $5~\mathrm{MHz}$ in the PAL system.

\vspace{3mm}
As discussed earlier, the visual acuity (i.e. the spatial resolution) of the human visual system is less than the half for color information than for luminance.
This property of human vision can be exploited in order to achieve significant video compression.
For the \ycbcr representation this served as the starting point for the subsampling of chroma signals.
In the analog case this phenomena allows the bandwidth reduction of chroma signals, therefore, in component systems the chroma signals are bandlimited to the half of the luma signal (resulting in a halved horizontal color resolution), while in composite video the color information is transmitted with even more reduced bandwidth.

\subsection{Composite video signal}

Anal√≥g √°tviteltechnika szempontj√°b√≥l a legegyszer≈±bb megold√°s a vide√≥jel tov√°bb√≠t√°s√°ra a 3 vide√≥komponens egyetlen √©rp√°ron val√≥ √°tvitele.
Ebben az esetben a luma √©s chroma komponensekb≈ël egyetlen √∫n. \textbf{kompozit} jelet kell k√©pzeni, hogy a vev≈ë oldalon az eredeti h√°rom komponens k√ºl√∂nv√°laszthat√≥.
A feladat megold√°s√°ra h√°rom---alapgondolat√°ban azonos---m√≥dszer l√©tezik, az NTSC, PAL √©s SECAM megold√°sok.
A rendszerek pontos m≈±k√∂d√©s√©t≈ël eltekintve a k√∂vetkez≈ë bekezd√©s az NTSC √©s PAL kompozitjelek k√©pz√©s√©nek alapelv√©t mutatja be.

A kompozit form√°tum az NTSC rendszer bevezet√©s√©vel ker√ºlt kidolgoz√°sra a l√©tez≈ë fekete-feh√©r TV-vev≈ëkkel kompatibilis anal√≥g sz√≠nes m≈±sorsz√≥r√°s megval√≥s√≠t√°s√°ra.
A feladat a m√°r l√©tez≈ë m≈±sorsz√≥r√≥ rendszerben alaps√°vban tov√°bb√≠tott luma jelhez (azaz a fekete-feh√©r jelhez) a sz√≠ninform√°ci√≥ olyan m√≥d√∫ hozz√°ad√°sa volt, hogy a l√©tez≈ë monokr√≥m vev≈ëkben a t√∂bbletinform√°ci√≥ minim√°lis l√°that√≥ hat√°st okozzon, m√≠g a sz√≠nes vev≈ë megfelel≈ëen k√ºl√∂n tudja v√°lasztani a luma √©s chroma jeleket.
Teh√°t m√°s sz√≥val a visszafele-kompatibilit√°s miatt az √∫j sz√≠nes rendszerben a luma jelet v√°ltozatlanul kellett √°tvinni. 
Minthogy az √°tvitelhez haszn√°lt RF spektrum jelent≈ës r√©sz√©t m√°r elfoglalt√°k a frekvenciaoszt√°sban k√ºld√∂tt egyes TV csatorn√°k (a k√©pinform√°ci√≥, √©s az FM modul√°lt hanginform√°ci√≥), √≠gy a luma √©s chroma komponensek csak ugyanabban a frekvencias√°vban ker√ºlhetnek tov√°bb√≠t√°sra.

Az alaps√°vi fekete-feh√©r TV jel fel√©p√≠t√©se egyszer≈± a m√°r bemutatott \ref{fig:PAL_frame} √°br√°n l√°that√≥ fel√©p√≠t√©ssel megegyez≈ë:
Egym√°s ut√°n, soronk√©nt tartalmazza a CRT elektron-√°gy√∫ vez√©rl≈ëfesz√ºlts√©g√©nek id≈ët√∂rt√©net√©t, amely teh√°t √≠gy a m≈±sor v√©tel√©vel teljesen val√≥s id≈ëben rajzolja soronk√©nt a kijelz≈ë k√©perny≈ëj√©re az $Y'(t)$ luma jel tartalm√°t.
Az egyes sorok √©s k√©pek kijelz√©se k√∂z√∂tt az elektron-√°gy√∫ kikapcsolt √°llapotban v√©ges id≈ë alatt fut vissza a k√∂vetkez≈ë sor, illetve k√©p elej√©re. 
Egy fekete-feh√©r TV sor fel√©p√≠t√©se az \ref{Fig:PAL_line} √°br√°n l√°that√≥.

%
\begin{figure}[]
	\centering
	\begin{minipage}[c]{0.65\textwidth}
	\begin{overpic}[width = 0.95\columnwidth ]{figures/PAL_line.png}
	\end{overpic} \end{minipage}\hfill
	\begin{minipage}[c]{0.35\textwidth}	\caption{Egyetlen TV sor luma jele √©s szinkron jelei a PAL rendszer id≈ëz√≠t√©sei mellett. Az NTSC eset√©ben a TV sor fel√©p√≠tse jellegere teljesen azonos, a PAL-t√≥l elt√©r≈ë id≈ëz√≠t√©sekkel.}
	\label{Fig:PAL_line}  \end{minipage}
\end{figure}
%

A val√≥s idej≈± √°tvitel/kijelz√©s elv√©b≈ël l√°that√≥, hogy a sz√≠ninform√°ci√≥ √°tvitele id≈ëoszt√°sban sem lehets√©ges, teh√°t a chroma jeleket a luma jelekkel azonos frekvencias√°vban √©s id≈ëben sz√ºks√©ges √°tvinni.
A megold√°s t√°rgyal√°sa el≈ëtt vizsg√°ljuk k√ºl√∂n a chroma jelek tov√°bb√≠t√°s√°nak m√≥dj√°t.

\paragraph{A sz√≠nseg√©dviv≈ë bevezet√©se:}
A sz√≠nform√°ci√≥t hordoz√≥ k√©t chroma jel ($Y'(t)-R'(t), Y'(t)-B'(t)$) egyid≈ëben t√∂rt√©n≈ë √°tvitele sor√°n alapvet≈ë feladat a k√©t anal√≥g jel egyetlen jell√© val√≥ √°talak√≠t√°sa.
Erre az kvadrat√∫ra amplit√∫d√≥modul√°ci√≥ ad lehet≈ës√©get, amely egy olyan modul√°ci√≥s elj√°r√°s, ahol az inform√°ci√≥t r√©szben a viv≈ëhull√°m amplit√∫d√≥j√°nak v√°ltoztat√°s√°val, r√©szben annak f√°zisv√°ltoztat√°s√°val k√≥doljuk (ezzel teh√°t k√©t f√ºggetlen jel vihet≈ë √°t egyszerre). 
Mind PAL, mind NTSC rendszer eset√©ben az emberi l√°t√°s sz√≠nekre vett alacsony felbont√°s√°t kihaszn√°lva a chroma jeleket er≈ësen (PAL eset√©ben pl. a luma jel √∂t√∂d√©re, $1~\mathrm{MHz}$-re) s√°vkorl√°tozz√°k, ezzel az apr√≥, nagyfrekvenci√°n reprezent√°lt r√©szleteket kisim√≠tj√°k. 
Ezut√°n a kvadrat√∫ramodul√°lt chroma jeleket pl. PAL eset√©n
\begin{equation}
c^{\mathrm{PAL}}(t) = \underbrace{U'(t)}_{\left( B'- Y'\right) / 2.03} \cdot \sin \omega_c t + \underbrace{V'(t)}_{\left( R'- Y'\right) / 1.14}  \cdot \cos \omega_c t
\label{Eq:PAL_cr}
\end{equation}
alakban √°ll√≠thatjuk el≈ë, ahol $\sin \omega_c t$ az √∫n. \textbf{sz√≠nseg√©dviv≈ë}, $\omega_c$ a sz√≠nseg√©dviv≈ë frekvencia, $U'(t)$ az √∫n. f√°zisban l√©v≈ë, $V'(t)$ pedig a kvadrat√∫rakomponens.
A kvadrat√∫ramodul√°lt sz√≠njelek teh√°t egyszer≈±en az √°tsk√°l√°zott sz√≠nk√ºl√∂nbs√©gi jelek f√°zisban √©s kvadrat√∫r√°ban l√©v≈ë sz√≠nseg√©dv√≠v≈ëvel val√≥ modul√°ci√≥j√°val √°ll√≠that√≥ el≈ë.

A sz√≠njelek demodul√°ci√≥ja koherens (f√°zishelyes) vev≈ëvel egyszer≈± alaps√°vba val√≥ lekever√©ssel √©s alul√°tereszt≈ë sz≈±r√©ssel val√≥s√≠that√≥ meg:
\begin{align}
\begin{split}
\sin x \cdot \sin x = \frac{1-\cos 2x}{2}&,\hspace{1cm}
\cos x \cdot \cos x = \frac{1+\cos 2x}{2} \\
\sin x &\cdot \cos x = \frac{1}{2}\sin 2x
\end{split}
\end{align}
trigonometrikus azonoss√°gok alapj√°n $U'(t)$ demodul√°ci√≥ja
\begin{multline}
c^{\mathrm{PAL}}_{\mathrm{QAM}}(t)\cdot \sin \omega_c t = U'(t)\cdot \sin \omega_c t\cdot \sin \omega_c t + V'(t) \cdot \cos \omega_c t  \cdot	\sin \omega_c t = \\
\frac{1}{2} U'(t) -
\underbrace{ \xcancel{ \frac{1}{2} U'(t)\cos 2 \omega_c t  + V'(t) \cdot \frac{1}{2}\sin 2 \omega_c t }}_{\text{alul√°tereszt≈ë sz≈±r√©s}}
\end{multline}
szerint t√∂rt√©nik, m√≠g $V'(t)$ demodul√°l√°sa hasonl√≥an $\sin \omega_c t$ lekever√©s szerint.
A megfelel≈ë demodul√°ci√≥hoz teh√°t a vev≈ëben a sz√≠nseg√©dviv≈ë f√°zishelye, koherens el≈ë√°ll√≠t√°sa elengedhetetlen.
\begin{figure}[]
	\centering
	\hspace{4mm}
	\begin{overpic}[width = 0.70\columnwidth ]{figures/QAM_mod_demod.png}
	\end{overpic}
	\caption{QAM modul√°ci√≥ √©s demodul√°ci√≥ folyamat√°br√°ja}
	\label{Fig:QAM_mod_demod}
\end{figure}

Az NTSC rendszerben a PAL-hoz hasonl√≥an a sz√≠njelek
\begin{equation}
c^{\mathrm{NTSC}}_{\mathrm{QAM}}(t) = I'(t) \cdot \sin \omega_c t + Q'(t) \cdot \cos \omega_c t
\end{equation}
alakban ker√ºltek √°tvitelre, ahol az in-phase √©s kvadrat√∫ra komponensek rendre
\begin{align}
\begin{split}
I'(t) &= k_1 (R'-Y') + k_2 (B'-Y) ,\\ 
Q'(t) &= k_3 (R'-Y') + k_4 (B'-Y).
\end{split}
\end{align}
A $k_{1-4}$ konstansokat √∫gy v√°lasztott√°k meg, hogy az in-phase √©s kvadrat√∫ra modul√°lt jelek nem k√∂zvetlen√ºl a k√©k √©s piros mer≈ëleges b√°zisvektorok (ld. \ref{Fig:ycbcr_gamut} √°bra), hanem ezek kb. $+20^{\circ}$ elforgatottja.
Az √≠gy kapott √∫j tengelyek a magenta-z√∂ld √©s t√ºrkiz-narancss√°rga tengelyek a k√∂zvetlen modul√°l√≥jelek.
Ennek oka, hogy √∫gy tal√°lt√°k, az emberi l√°t√°s felbont√°sa j√≥val nagyobb t√ºrkiz-narancss√°rga k√∂zti v√°ltoz√°sokra, mint a magenta-z√∂ld k√∂z√∂tt.
Ezt kihaszn√°lva a magenta-z√∂ld $Q'(t)$ sz√≠njeleket az $I'(t)$ jelhez k√©pest is jobban s√°vkorl√°tozt√°k, s√°vsz√©less√©g-takar√©koss√°g c√©lj√°b√≥l.
A PAL rendszer bevezet√©s√©nek idej√©re azonban kider√ºlt, hogy ez rendszer felesleges t√∫lbonyol√≠t√°sa, √≠gy az √∫j rendszerben megmaradtak az eredeti sz√≠nk√ºl√∂nbs√©gi jelek modul√°ci√≥j√°n√°l.

\vspace{3mm}
Vizsg√°ljuk v√©g√ºl a modul√°lt sz√≠njel fizikai jelent√©s√©t, az egyszer≈±s√©g kedv√©√©rt $c^{\mathrm{PAL}}(t)$ eset√©re (PAL rendszerben)!
Az \eqref{Eq:PAL_cr} egyenlet egyszer≈± trigonometrikus azonoss√°gok alapj√°n √°t√≠rhat√≥ a 
\begin{equation}
c^{\mathrm{PAL}}_{\mathrm{QAM}}(t) = \sqrt{U'(t)^2 + V'(t)^2} \, \sin \left( \omega_c t + \arctan \frac{V'(t)}{U'(t)} \right)
\end{equation}
pol√°r alakra.
Minthogy a modul√°l√≥ $U',V'$ jelek a sz√≠nk√ºl√∂nbs√©gi jelekkel ar√°nyosak, √≠gy a fenti kifejez√©st \eqref{eq:saturation_1} √©s \eqref{eq:hue}-val √∂sszehasonl√≠tva meg√°llap√≠that√≥, hogy a QAM modul√°lt jel egy olyan szinuszos viv≈ë, amelynek pillanatnyi amplit√∫d√≥ja a tov√°bb√≠tott sz√≠npont tel√≠tetts√©g√©t, pillanatnyi f√°zisa a sz√≠npont sz√≠nezet√©t adja meg.

\begin{figure}[]
	\centering
	\hspace{4mm}
	\begin{overpic}[width = 0.50\columnwidth ]{figures/SMPTE_Color_Bars.png}
\small
\put(-7	,0){(a)}
	\end{overpic} \hfill
	\begin{overpic}[width = 0.395\columnwidth ]{figures/vectorscope.png}
\small
\put(-10,0){(b)}
	\end{overpic}
	\caption{Egy gyakran alkalmazott vizsg√°l√≥k√©p (SMPTE color bar) (a) √©s vektorszk√≥ppal √°br√°zolva (b).}
	\label{Fig:bar_pattern_vscope}
\end{figure}

A sz√≠nseg√©dviv≈ë amplit√∫d√≥j√°nak √©s f√°zis√°nak egyszer≈± √©rtelmezhet≈ës√©ge miatt az NTSC √©s PAL jeleket gyakran vizsg√°lt√°k √∫n. vektorszk√≥p seg√≠ts√©g√©vel j√≥l meghat√°rozott vizsg√°l√≥√°br√°k megjelen√≠t√©se mellett.
A vektorszk√≥p kijelz≈ëje gyakorlatilag a \ref{Fig:ycbcr_gamut} √°br√°n is l√°that√≥ $B'-Y', B'-Y'$ t√©rben jelen√≠ti meg a teljes k√©ptartalom (azaz egyszerre az √∂sszes k√©ppont) chroma jeleit, $Y'$-t√≥l f√ºggetlen√ºl a demodul√°lt chroma-jelek megjelen√≠t√©s√©vel.
A vektorszk√≥p gyakorlatilag egy olyan oszcilloszk√≥p, amelynek $x$ kit√©r√©s√©t a demodul√°lt $B'-Y'$, $y$-kit√©r√©st a demodul√°lt $R'-Y'$ jel vez√©rli, √≠gy a teljes k√©ptartalom sz√≠nezet√©t szinte egyszerre jelen√≠ti meg az el≈ëre felrajzol vizsg√°lati r√°cson.
Egy tipikus vizsg√°l√≥ √°bra √©s annak vektorszk√≥pos k√©pe l√°that√≥ a \ref{Fig:bar_pattern_vscope} √°br√°kon.
A vektorszk√≥p alkalmaz√°s√°nak el≈ënye, hogy az esetleges amplit√∫d√≥ √©s f√°zishib√°b√≥l sz√°rmaz√≥ tel√≠tetts√©g √©s sz√≠nezethib√°k j√≥l l√°that√≥v√° v√°lnak a kijelz≈ën az egyes felvet√≠tett pontok ''√∂sszesz≈±k√ºl√©se/t√°gul√°sa'', illetve a teljes konstell√°ci√≥ elfordul√°sak√©nt.
Megjegyezhet≈ë, hogy a mai digit√°lis videojeleket is gyakran √°br√°zolj√°k szoftveres vektorszk√≥pon az egyes pixelek sz√≠nezet√©nek vizsg√°lat√°hoz.

\paragraph{A sz√≠nseg√©dviv≈ë frekvencia:}
Vizsg√°ljuk most, hogyan v√°laszthat√≥ meg a sz√≠nseg√©dviv≈ë $\omega_c$ viv≈ëfrekvenci√°ja √∫gy, hogy a QAM modul√°lt $c^{\mathrm{PAL}}(t)$ jelet a luma jelhez hozz√°adva a vev≈ë oldalon lehets√©ges legyen a vett $c^{\mathrm{PAL}}(t) + Y'(t)$ jelb≈ël az eredeti chroma √©s luma jelek sz√©tv√°laszt√°sa!

A jelek vev≈ëoldali sz√©tv√°laszt√°s√°ra a luma √©s chroma jelek spektruma ad lehet≈ës√©get:
L√°thattuk, hogy a vide√≥jel az egyes TV sorokban megjelen√≠tend≈ë vil√°goss√°g √©s sz√≠ninform√°ci√≥ sorfolytonos id≈ët√∂rt√©netek√©nt foghat√≥ fel.
Term√©szetes k√©peken a k√©ptartalom sorr√≥l sorra csak lassan v√°ltozik (term√©szetesen a k√©ptartalomban jelenl√©v≈ë v√≠zszintes √©leket lesz√°m√≠tva), √≠gy mind a luma, mind a chroma jelek √∫n. kv√°zi-periodikusak, azaz k√∂zel periodikusak.
Jel- √©s rendszerelm√©leti ismereteink alapj√°n tudjuk, hogy egy periodikus jel spektruma vonalas, a jelfrekvencia eg√©sz sz√°m√∫ t√∂bbsz√∂r√∂sein tartalmaz csak komponenseket.
Ennek megfelel≈ëen mind a luma, mind a chroma jelek spektruma k√∂zel vonalas: az energi√°juk a sorfrekvencia eg√©sz sz√°m√∫ t√∂bbsz√∂r√∂sein csom√≥sodik.
Term√©szetesen a luma jel az alaps√°vban helyezkedik el ($0~\mathrm{Hz}$ k√∂rnyezet√©ben), kb. $5.6~\mathrm{MHz}$ s√°vsz√©less√©gben\footnote{Ez a s√°vsz√©less√©g eredm√©nyezi az azonos horizont√°lis √©s vertik√°lis k√©pfelbont√°st.}.
A QAM modul√°lt chroma jel spektruma a s√°vkorl√°toz√°s miatt keskenyebb ($1~\mathrm{MHz}$), √©s k√∂z√©ppontj√°t $\omega_c$ viv≈ëfrekvencia hat√°rozza meg.
\begin{figure}[]
	\centering
	\hspace{4mm}
	\begin{overpic}[width = 0.80\columnwidth ]{figures/LC_interlace.png}
	\end{overpic} \hfill
	\caption{A luma √©s chroma jelek spektr√°lis k√∂zbesz√∂v√©s√©nek alapelve a teljes spektrumokat √°br√°zolva (a) √©s a spektr√°lis csom√≥kat felnagy√≠tva (b)}
	\label{Fig:YC_interlace}
\end{figure}

A luma-chroma jel √∂sszegz√©se ennek ismeret√©ben egyszer≈±: 
Az $\omega_c$ viv≈ëfrekvencia megfelel≈ë megv√°laszt√°s√°val el√©rhet≈ë, hogy a chroma jel spektrumvonalai (spektrumcsom√≥i) √©ppen a luma jel spektrumvonalai k√∂z√© essen, azaz a spektrumukat √°tlapol√≥d√°s n√©lk√ºl k√∂zbesz≈ëhetj√ºk.
Az elj√°r√°s alap√∂tlet√©t \ref{Fig:YC_interlace} √°bra illusztr√°lja $f_{\mathrm{H}}$-val a sorfrekvenci√°t jel√∂lve.
A sz√©tv√°laszthat√≥s√°g felt√©tele ekkor 
\begin{equation}
f_c = f_{\mathrm{H}} \cdot \left( \mathrm{n} + \frac{1}{2}\right), \hspace{1.5cm} \mathrm{n} \in \mathcal{N} 
\end{equation}
azaz a sz√≠nseg√©dviv≈ë frekvenci√°ja a sorfrekvencia fel√©nek eg√©sz sz≈±m√∫ t√∂bbsz√∂r√∂s√©nek kell, hogy legyen \footnote{Megjegyezhet≈ë, hogy PAL eset√©ben az el≈ëre adott sorfrekvenci√°hoz egyszer≈± volt a sz√≠nseg√©dviv≈ë-frekvencia megv√°laszt√°sa, m√≠g NTSC eset√©n bizonyos okok miatt a sorfrekvencia √©s ebb≈ël k√∂vetkez≈ëen a k√©pfrekvencia megv√°ltoztat√°s√°ra volt sz√ºks√©g. 
Innen sz√°rmaznak a ma is haszn√°latos $59.94$ √©s $29.97~\mathrm{Hz}$ k√©pfrekvenci√°k, amelyeket a k√∂vetkez≈ë fejezet t√°rgyal r√©szletesen.}.

\paragraph{A CVBS kompozit vide√≥jel √©s luma-chroma sz√©tv√°laszt√°s:}
Ennek ismeret√©ben v√©g√ºl a teljes kompozitjel a 
\begin{equation}
\text{CVBS}(t) = \mathrm{Sy}(t) + Y'(t) + c_{\mathrm{QAM}}(t)
\end{equation}
alakban √°ll el≈ë, ahol $Y'$ a luma jel, $c_{\mathrm{QAM}}$ a QAM modul√°lt chroma jelek √©s $\mathrm{S\!y}(t)$ a kiolt√°si id≈ëben jelen l√©v≈ë sorszinkron √©s k√©pszinkron jelek.
A CVBS elnevez√©s gyakori szinon√≠ma a kompozit vide√≥jelre, jelent√©se C: color, V: video (luma), B: blanking (azaz kiolt√°s) √©s S: sync (azaz szinkronjelek).

Az √≠gy l√©trehozott vide√≥jel a fekete-feh√©r k√©phez k√©pest csak a modul√°lt sz√≠nseg√©dviv≈ët tartalmazza t√∂bbletinform√°ci√≥nak.
Egyszer≈± fekete-feh√©r vev≈ën a CVBS jelet megjelen√≠tve a sz√≠ninform√°ci√≥ nagyfrekvenci√°s zajk√©nt, pontoz√≥d√°sk√©nt (√∫n. \href{http://www.techmind.org/colrec/}{chroma dots}) jelenik csak meg a kijelz≈ën, √≠gy a visszafel√© kompatibilit√°s biztos√≠tva volt.
Sz√≠nes vev≈ëkben a CVBS jelb≈ël a luma √©s chromajel elm√©letileg f√©s≈±sz≈±r√©ssel szepar√°lhat√≥ a sorfrekvencia fel√©nek eg√©sz sz√°m√∫ t√∂bbsz√∂r√∂seit elnyomva.
Ez ide√°lisan egy soridej≈± k√©sleltet√©st ig√©nyel \footnote{A bizony√≠t√°shoz vizsg√°ljuk $h(t) = \delta(t) + \delta(t-t_{\mathrm{H}})$ sz≈±r≈ë √°tviteli karakterisztik√°j√°t, amely sz≈±r≈ë a jelb≈ël kivonja $t_H$-val k√©sleltetett √∂nmag√°t!}.
A f√©s≈±sz≈±r≈ës luma-chroma szepar√°ci√≥ lehet≈ës√©ge m√°r az NTSC fejleszt√©s√©nek idej√©n ismert volt, azonban a sz√ºks√©ges soridej≈± k√©sleltet≈ë nem √°llt rendelkez√©sre, ez√©rt a korai NTSC vev≈ëk egyszer≈± alul/fel√ºl√°tereszt≈ë sz≈±r≈ëkkel, vagy egyszer≈± chroma jelre √°ll√≠tott lyuksz≈±r≈ëkkel szepar√°lt√°k a luma-chroma jeleket.
Ennek eredm√©nyek√©pp m√©g a sz√≠nes vev≈ëkben is a chroma jelen kisfrekvenci√°s tartalomk√©nt jelen lehetett a vil√°goss√°ginform√°ci√≥ l√°that√≥ \href{https://en.wikipedia.org/wiki/Dot_crawl}{hat√°ssal a megjelen√≠tett k√©pre}.
A megfelel≈ë anal√≥g PAL f√©s≈±sz≈±r≈ë-tervez√©s m√©g a 90-es √©vekben is akt√≠v \href{https://www.renesas.com/in/en/www/doc/application-note/an9644.pdf}{K+F} alatt √°ll√≥ ter√ºlet volt.

\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.45\columnwidth ]{figures/ntsc_color_line.png}
	\end{overpic} \hfill
	\begin{overpic}[width = 0.48\columnwidth ]{figures/Waveform_monitor.jpg}
	\end{overpic} \hfill
	\caption{Az SMPTE color bar vizsg√°l√≥ √°br√°nak egy, illetve k√©t sor√°nak hull√°mform√°ja sematikusan (a), √©s egy hull√°forma monitoron (b) vizsg√°lva}
	\label{Fig:NTSC_line}
\end{figure}

Az elmondottak alapj√°n az NTSC rendszerben a \ref{Fig:bar_pattern_vscope} √°br√°n l√°that√≥ vizsg√°l√≥√°br√°nak egy sor√°nak kompozit √°br√°zol√°s√°t a \ref{Fig:NTSC_line} mutatja be jellegre helyesen, √©s egy konkr√©t hull√°mforma monitoron m√©rve.
Az √°br√°n megfigyelhet≈ë az egyes oszlopokhoz tartoz√≥ hull√°malak: l√°that√≥, hogy a cs√∂kken≈ë vil√°goss√°g√∫ oszlopokra (amelyek vil√°goss√°g√°t szaggatott vonal jelzi) hogyan √ºltett√©k r√° a QAM modul√°lt chroma jeleket.
Az els≈ë √©s utols√≥ feh√©r, illetve fekete oszlop eset√©n a chroma jelek amplit√∫d√≥ja z√©rus (feh√©rpont), egy√©b esetekben a szinuszos sz√≠nseg√©dviv≈ë amplit√∫d√≥ja az oszlopok sz√≠n√©nek tel√≠tetts√©g√©vel, f√°zisa a sz√≠nezet√ºkkel ar√°nyos.
Megjegyezz√ºk, hogy a t√©nyleges hull√°mforma m√°r √°tsk√°l√°zott chroma jeleket √°br√°zol, amely √°tsk√°l√°z√°s √©pp az√©rt t√∂rt√©nik, hogy a teljes CVBS jel belef√©rjen a fizikai interface dinamikatartom√°ny√°ba (ez term√©szetesen a nagy tel√≠tetts√©g≈± sz√≠nek eset√©n okozna probl√©m√°t).
Ez magyar√°zza teh√°t az eddig figyelmen k√≠v√ºl hagyott 2.03 √©s 1.14 sk√°lafaktorokat pl. \eqref{Eq:PAL_cr} eset√©ben.


Az NTSC jel fel√©p√≠t√©se alapj√°n egy√©rtelm≈±, hogy a megfelel≈ë sz√≠nek helyre√°ll√≠t√°s√°hoz a vev≈ëben a sz√≠nseg√©dviv≈ë f√°zis√°nak nagyon pontos ismerete sz√ºks√©ges.
Ahhoz, hogy ez biztos√≠tva legyen a sorkiolt√°si id≈ëben az √∫n. h√°ts√≥ v√°llra (ld. \ref{Fig:PAL_line} √°bra) be√ºltet√©sre ker√ºlt n√©h√°ny peri√≥dusnyi (9) k√©ptartalom n√©lk√ºli referenciaviv≈ë, az √∫n. color burst, vagy burst jel.
Ez a burst jel megfigyelhet≈ë a \ref{Fig:NTSC_line} √°br√°n is.

Ennek ellen√©re az NTSC rendszer tov√°bbra is f√°zis√©rz√©keny volt, hiszen f√°zishib√°t a vev≈ëben is b√°rmelyik alkatr√©sz okozhatott.
A QAM modul√°ci√≥ jelege miatt m√°r a legkisebb f√°zishiba is l√°that√≥ sz√≠nezetv√°ltoz√°st okozott a megjelen√≠tett k√©pen.
A PAL rendszer tervez√©s√©nek egyik f≈ë c√©lja √©pp ez√©rt a rendszer f√°zishib√°ra vett √©rz√©kenys√©g√©nek cs√∂kkent√©se volt

\paragraph{A PAL rendszer:}
M√≠g az egyszer≈± NTSC rendszer m√°r 1953-ban bevezet√©sre ker√ºlt Amerik√°ban, addig Eur√≥p√°ban eg√©szen az 1960-as √©veikg v√°rtak a sz√≠nes m≈±sorsz√≥r√°s bevezet√©s√©re.
Ennek oka, hogy az elt√©r≈ë h√°l√≥zati frekvencia miatt az NTSC-t nem lehetett egy az egyben √°temelni Eur√≥p√°ba (ld. k√©s≈ëbb).
Mire az eur√≥pai rendszert kifejlesztett√©k, az NTSC rendszer j√≥ n√©h√°ny gyenges√©g√©re f√©ny der√ºlt, √≠gy az √∫jonnan kifejlesztett PAL (Phase Alternate Lines) ezek kijav√≠t√°s√°t c√©lozta f≈ëk√©nt meg.
Ennek eredm√©nyek√©pp a PAL rendszer m√°s QAM modul√°ci√≥val dolgozik (a chroma jelek k√∂zvetlen√ºl a modul√°l√≥jelek), elt√©r≈ë a sz√≠nseg√©dviv≈ë frekvencia, √©s legfontosabb √∫j√≠t√°sk√©nt: egy egyszer≈± megold√°ssal szinte √©rz√©ketlen a f√°zishib√°ra.
\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.45\columnwidth ]{figures/PAL1.png}
	\end{overpic} \hfill
	\begin{overpic}[width = 0.45\columnwidth ]{figures/PAL2.png}
	\end{overpic} \hfill
	\caption{Az SMPTE color bar vizsg√°l√≥ √°br√°nak egy, illetve k√©t sor√°nak hull√°mform√°ja sematikusan (a), √©s egy hull√°forma monitoron (b) vizsg√°lva}
	\label{Fig:PAL1}
\end{figure}

L√°thattuk, hogy a vev≈ë oldal√°n b√°rmilyen f√°zishiba a sz√≠nezet j√≥l l√°that√≥ torzul√°s√°t okozza.
Mivel a f√°zishiba gyakran elker√ºlhetetlen, ez√©rt hat√°s√°nak kik√ºsz√∂b√∂l√©s√©re a PAL rendszer a k√∂vetkez≈ë egyszer≈± megold√°st alkalmazza:
\begin{itemize}
\item Az ad√≥ oldalon (a PAL jel l√©trehoz√°sa sor√°n) k√©pezz√ºk QAM modul√°ci√≥ sor√°n a V' chromajel el≈ëjel√©t minden m√°sodik TV-sorban neg√°ljuk meg, azaz sorr√≥l sorra ford√≠tott el≈ëjellel vigy√ºk √°t (ez ekvivalens a sorr√≥l sorra v√°ltoz√≥ $\pm \cos \omega_c t$ viv≈ëvel val√≥ modul√°ci√≥val)!
Az elj√°r√°s szeml√©ltet√©s√©re tegy√ºk fel, hogy k√©t egym√°s ut√°na sorban minden horizont√°lis poz√≠ci√≥ban a sz√≠ninform√°ci√≥ azonos.
Ekkor egy adott pontra az n. √©s (n+1). sorban √°tvitt $U',V'$ jeleket a \ref{Fig:PAL1} (a) √°bra szeml√©lteti pl egy lila k√©ppont √°tvitele eset√©n.
\item Tegy√ºk fel, hogy a vev≈ë oldalon a vett jelhez $\Delta \alpha$ f√°zishiba ad√≥dik az √°tvitel √©s demodul√°ci√≥ sor√°n.
Term√©szetesen a f√°zishiba hat√°s√°ra az √≠gy vett sz√≠nvektor mind az n., mind az (n+1). sorban azonos ir√°nyba fordul az $U'-V'$ konstell√°ci√≥s diagramon (azaz a $R'-Y', B'-Y'$ s√≠kon), ahogy az a \ref{Fig:PAL1} (b) √°br√°n l√°that√≥.
\item A vev≈ë oldal√°n forgassuk vissza minden m√°sodik sorban a vett $V'$ komponens el≈ëjel√©t √©s k√©pezz√ºk az (n+1). sor √©s az n. sor √°tlag√°t.
Ezzel term√©szetesen a sz√≠njelek vertik√°lis felbont√°s√°t cs√∂kkentj√ºk (az √°tlagk√©pz√©s az apr√≥ r√©szleteket elsim√≠tja), azonban ennek eredm√©nye az emberi szem sz√≠nezetre vett felbont√°sa eredm√©nyek√©pp az inform√°ci√≥vesztes√©g nem l√°that√≥ (a horizont√°lis felbont√°s m√°r egy√©bk√©nt is jelent≈ësen lecs√∂kkent az egyszer≈± s√°vkorl√°toz√°s hat√°s√°ra).
K√∂nnyen bel√°that√≥, hogy a k√©t vektor √°tlag√°t k√©pezve √©ppen az eredeti, hibamentes sz√≠nvektort kapjuk eredm√©ny√ºl.
K√©t sor eset√©n azonos sortartalom eset√©n teh√°t ezzel az egyszer≈± tr√ºkkel a f√°zishiba hat√°sa teljesen kik√ºsz√∂b√∂lhet≈ë, m√≠g levezethet≈ë, hogy v√°ltoz√≥ sortartalom eset√©n a f√°zishiba az √°tlagvektor hossz√°nak cs√∂kken√©s√©t okozza, teh√°t sz√≠nezetv√°ltoz√°s helyett csak tel√≠tetts√©gv√°ltoz√°st okoz.
\end{itemize}
A bemutatott m√≥dos√≠tott modul√°ci√≥s m√≥dszerrel m√©g ar√°nylag nagy f√°zishib√°k hat√°sa is minim√°lis hat√°ssal van a megjelen√≠tett k√©pre.
Az ok, hogy m√©gis t√∂bb, mint egy √©vtizedet kellett v√°rni a PAL rendszer bevezet√©s√©re az volt, hogy a m√≥dszer alkalmaz√°s√°hoz (az √°tlagol√°s elv√©gz√©s√©hez) a vide√≥jel soridej≈± k√©sleltet√©s√©re volt sz√ºks√©g.
Ez az 50-es √©vekben anal√≥g m√≥don nem megoldhat√≥ probl√©ma volt amely a PAL implement√°l√°s√°t h√°tr√°ltatta.

A PAL bevezet√©s√©t v√©g√ºl az olcs√≥n t√∂meggy√°rthat√≥ √∫n akusztikus m≈±vonalak megjelen√©se tette lehet≈ëv√©.
Ez az akusztikus m≈±vonal, vagy \href{https://www.google.com/search?q=PAL+delay+line&client=firefox-b-d&sxsrf=ALeKk03EUTzVwc7dkYJFnEK-nlEI_p3hng:1586379019108&source=lnms&tbm=isch&sa=X&ved=2ahUKEwi90Kav2tnoAhXJ-ioKHWz6AJcQ_AUoAXoECA0QAw&biw=1407&bih=675}{PAL delay line} egy egyszer≈± √ºvegt√∂mb, amelyre egy piezo aktu√°tor √©s piezo vev≈ë csatlakozik.
Az ad√≥ a TV chroma jel√©vel ar√°nyos mechanikai rezg√©seket (ultrahang) \href{https://www.youtube.com/watch?v=-qerYLM-eEg}{hoz l√©tre}, amely t√∂bbsz√∂r√∂s visszaver≈ëd√©sek ut√°n √©pp egy sorid≈ënyi k√©sleltet√©st szenvedve √©r a vev≈ë elektr√≥d√°hoz.
Az ultrahang alap√∫ k√©sleltet≈ëvonalak eg√©szen a 90-es √©vek v√©g√©ig a PAL dek√≥derek r√©sz√©t k√©pezt√©k.


\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.82\columnwidth ]{figures/PAL_coder.png}
	\end{overpic} \hfill
	\caption{A PAL k√≥dol√≥ fel√©p√≠t√©se}
	\label{Fig:PAL_coder}
\end{figure}
Az egyszer≈± PAL k√≥dol√≥ fel√©p√≠t√©se az eddig elmondottak alapj√°n a \ref{Fig:PAL_coder} √°br√°n l√°that√≥.
R√∂viden √∂sszefoglalva, mind a PAL, mind NTSC eset√©n a kompozitjel l√©trehoz√°sa sor√°n a feladat a Gamma-torz√≠tott $R',G',B'$ jelekb≈ël az $Y',U',V$ (PAL) √©s $Y',I',Q'$ (NTSC) jelek l√©trehoz√°sa, majd az $U',V'$ √©s $I'Q'$ jelek megfelel≈ë QAM modul√°ci√≥ja. 
Az √≠gy l√©trehozott jeleket √∂sszeadva √©s a kiolt√°si id≈ëben tov√°bb√≠tott szinkronjelekkel ell√°tva el≈ë√°ll a CVBS kompozit jel.

\vspace{3mm}
A kompozit vide√≥jel fizikai interface megval√≥s√≠t√°sa szabv√°nyr√≥l szabv√°nyra v√°ltoz√≥.
Konzumer felhaszn√°l√°s (pl. k√©zikamer√°k, vide√≥lej√°tsz√≥k, DVD lej√°tsz√≥k) szempontj√°b√≥l a legelterjedtebb csatlakoz√≥ a s√°rga jel√∂l√©s≈± RCA v√©gz≈ëd√©s, amely az esetleges k√≠s√©r≈ë hangt√≥l szigetelve, k√ºl√∂n √©rp√°ron tov√°bb√≠tja a kompozit vide√≥jelet.
\begin{figure}[]
	\centering
	\begin{minipage}[c]{0.6\textwidth}
	\begin{overpic}[width = 0.45\columnwidth ]{figures/Composite-video-cable.jpg}
	\end{overpic} 
		\begin{overpic}[width = 0.45\columnwidth ]{figures/s_video.jpg}
	\end{overpic} \end{minipage}\hfill
	\begin{minipage}[c]{0.4\textwidth}
	\caption{Konzumer alkalmaz√°sokhoz haszn√°lt s√°rga jel√∂l√©s≈± RCA csatlakoz√≥ (a) √©s a luma-QAM chroma jeleket k√ºl√∂n √©rp√°ron √°tviv≈ë S-vide√≥ csatlakoz√≥ (b)}
	\label{Fig:composite_video}  \end{minipage}
\end{figure}

A kompozit √©s komponens jelek k√∂zti kompromisszumk√©nt az S-video form√°tum a luma √©s chroma jeleket k√ºl√∂n √©rp√°ron viszi √°t.
Ezt lesz√°m√≠tva az interface jele teljesen a kompozit vide√≥val azonosak, tov√°bb√≠that ak√°r NTSC, ak√°r PAL (ak√°r SECAM) vide√≥komponenseket:
A luma teh√°t v√°ltozatlanul alaps√°vban, m√≠g a chroma a sz√≠nseg√©dviv≈ëvel modul√°lva ker√ºl √°tvitelre.
A chroma jelek modul√°ci√≥ja elker√ºlhetetlen, hiszen a k√©t f√ºggetlen sz√≠nk√ºl√∂nbs√©gi jel egy √©rp√°rra val√≥ √ºltet√©s√©hez azokat legal√°bb a s√°vsz√©less√©g√ºkkel megegyez≈ë frekvenci√°j√∫ viv≈ëjellel val√≥ modul√°ci√≥ sz√ºks√©ges az √°tlapol√≥d√°s elker√ºl√©s√©hez.
Az S-video szabv√°ny csatlakoz√≥ja a \ref{Fig:composite_video} (b) √°br√°n l√°that√≥.


\subsection{Component video signal}

The idea of transmitting the video signal by separated components is straightforward, still, it was allowed by technology only decades after composite video was introduced:
While interfaces for device-to-device video transmission could be achieved even with analog data, the broadcasting of component video could be only resolved with the introduction of digital video standards.
In case of component video the transmitted signals are directly the luma and the chroma signals (or less often the $R'G'B'$ signals), or more precisely the \ypbpr components.

The \ypbpr representation consists of the three following signals:
\begin{itemize}
\item $Y'$: the luma component, calculated by the luma coefficients defined by the RGB primaries.
The required sync pulses are added to the luma component.
Therefore, a device with composite video output can be connected to the $Y'$ interface of a display with component input.
As a result the black and white image is displayed with the modulated chroma signal resulting in high frequency noise (,,chroma dotting'') on the screen.
\item $P'_{\mathrm{B}},P'_{\mathrm{R}}$: the $B'-Y', R'-Y'$ chroma components, rescaled to the actual physical interface, usually requiring the dynamic range of $\pm 0.5~\mathrm{V}$.
Notation $P$ is the legacy of the composite systems, where color information is carried by the \textbf{P}hase of the subcarrier.
\end{itemize}
\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.45\columnwidth ]{figures/1280px-Component-cables.jpg}
	\end{overpic} \hfill
	\begin{overpic}[width = 0.45\columnwidth ]{figures/YPBPR_signals.png}
	\end{overpic} \hfill
	\caption{RCA connectors, applied frequently for the physical interface of component video (a) and the component video signals of the bar test pattern (b)}
	\label{Fig:comp_video}
\end{figure}
Similarly to composite video, the actual parameters of the component formats depend on the region of application: 
components formats can be considered as the transmission of NTSC and PAL video formats without the QAM modulation of the chroma signals.
Therefore, both 625 and 525 scan line interlaced component formats exist with $60~\mathrm{Hz}$ and $50~\mathrm{Hz}$ field rate.
A simple example is depicted for the separately transmitted \ypbpr signals in case of the SMPTE color bar test pattern is depicted in Figure \ref{Fig:comp_video} (b).

In consumer electronic the component video interface is equipped with RCA connectors, with the red and blue cables carrying the red and blue chroma signals and the green connector transmitting the luma information.

\hspace{3mm}
Finally, from the numerous analog video interfaces two most widespread are mentioned here:
\begin{itemize}
\item The SCART connector (or EuroSCART, shorthand for Syndicat des Constructeurs d'Appareils Radior√©cepteurs et T√©l√©viseurs) was designed for the transmission of bidirectional composite, S-video and RGB components in the same time, with also carrying stereo audio and digital signing signals in the same time.
Before the advent of the HDMI interface SCART connectors also allowed the transmission of high definition 1080p format via \ypbpr component signals.
The typical 21-pin SCART connector is depicted in Figure \ref{Fig:scart_vga} (a).
\item The VGA (Video Graphics Array) connector is still a commonly used analog component interface between video cards and displays (external monitors, projectors, etc.).
The VGA interface transmits analog RGB components (in the color space of the video card) along with dedicate vertical and horizontal sync (VSYNC and HSYNC) cables.
Nowadays the VGA interface is superseded with DVI, HDMI and DisplayPort digital interfaces.
\end{itemize}

\begin{figure}[]
	\centering
	\begin{minipage}[c]{0.63\textwidth}
	\begin{overpic}[width = 0.47\columnwidth ]{figures/scart.jpg}
	\end{overpic} \hfill
		\begin{overpic}[width = 0.4\columnwidth ]{figures/vga.jpg}
	\end{overpic} \end{minipage}\hfill
	\begin{minipage}[c]{0.35\textwidth}
	\caption{The analog composite/component SCART (a) and RGB component VGA (a) connectors}
	\label{Fig:scart_vga}  \end{minipage}
\end{figure}

\section{Digital video formats}
	
\subsection{The SD format}

The first digital video format was developed by the ITU (International Telecommunication Union) and published in Rec. 601 (or ITU-601) in 1982\footnote{The CCIR (the predecessor of ITU) received the 1982‚Äì83 Technology and Engineering Emmy Award for its development}.

The SD format is basically the digital representation of the component analog formats, discussed in the foregoing:
The structure of digital video is obtained by the sampling of the analog video signal, as depicted in Figure \ref{fig:PAL_frame}, containing all the blanking intervals besides the active video content.
Therefore, digital video is the direct digitized version of the \ypbpr signals.
As already discussed in the previous chapter, the components of the video format are the digital representation of the color pixels, referred to as the \ycbcr components.
The signal processing scheme of digital video representation is illustrated in Figure \ref{Fig:SD_production}.
\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.8 \columnwidth ]{Figures/YCbCr_production.png}
	\end{overpic}
	\caption{Production of SD video format by the digitization of \ypbpr components}
	\label{Fig:SD_production}
\end{figure}

The digitization of the analog video signal consists of two main steps:
\begin{itemize}
\item sampling of the continuous video signal with a-priori antialiasing filtering
\item quantization of the continuous signal levels to discrete codes
\end{itemize}
The questions of quantization, i.e. digital representation of the individual pixels has been already discussed in the previous chapter.
Still, the parameters of sampling---or more specifically the sampling frequency---needs to be specified, defining the number of pixels per line, which, along with the number of lines gives the spatial resolution of the digital format.

\paragraph*{Sampling frequency of the video signal:\\}
The sampling frequency of the analog video components was chosen based on the following considerations:
\begin{itemize}
\item For several decades analog formats varied between from region to region due to the co-existence of NTSC, PAL and SECAM systems.
As a straightforward endeavour, a basic goal was to find a common sampling frequency, compatible with all the existing analog formats.
Furthermore, orthogonal sampling was an obvious need, meaning that in each system a single scan line should contain an integer number of samples (pixels).
Mathematically these requirements can be formulated, as the line period time has to be dividable by the sampling period, and equivalently
the sampling frequency has to be the multiple of the line frequency both in the PAL and the NTSC system, satisfying
\begin{equation}
f_s = n \cdot f_H^{\mathrm{PAL}} = m \cdot f_H^{\mathrm{NTSC}},
\end{equation}
%
where $n, m$ are integers.
The line frequencies in the two systems are given by
\begin{align}
f_H^{\mathrm{PAL}} &= 25 \cdot 625 = 15625~\mathrm{Hz} \\
f_H^{\mathrm{NTSC}} &= 30 \cdot \frac{1000}{1001} \cdot 525 = 15734.2~\mathrm{Hz} ,
\end{align}
with the smallest common multiple being
\begin{equation}
144 \cdot f_H^{\mathrm{PAL}} = 143 \cdot f_H^{\mathrm{NTSC}} = 2.25~\mathrm{MHz}.
\end{equation}
Therefore, the sampling frequency must be chosen as the multiple of $2.25~\mathrm{MHz}$.
\item On the other hand, according to the sampling theory, the sampling frequency has to be at least twice the bandwidth of the sampled signal in order to avoid aliasing artifacts.
In the foregoing it was discussed that---by taking also the Kell effect into consideration---the bandwidth of the luma signal is around $5.6~\mathrm{MHz}$, with the chroma bandwidth being the half of it.
\end{itemize}
The smallest frequency satisfying both requirements is given by 
\begin{equation}
f^{\mathrm{Y,SD}}_s = 13.5~\mathrm{MHz},
\end{equation}
being chosen as the sampling frequency of the luma signal of standard definition video.
As the chroma signals are bandlimited to the half of luma signal due to the lower visual acuity of the HVS, therefore, the chroma signals are sampled with halved sampling frequency ($f^{\mathrm{Ch,SD}}_s = 6.75~\mathrm{MHz}$).

The number of pixels in a scan line---given by the line period time divided by the sampling interval---is $N_{H,t} = \frac{T_H}{1/f_s} = 858$ pixels in the NTSC and $864$ in the PAL system, including the horizontal blanking intervals as well.
%
\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.65 \columnwidth ]{Figures/SD_formats.png}
	\end{overpic}
	\caption{The SD video format in the American and European systems}
	\label{Fig:SD_format}
\end{figure}
For the sake of further unification of the standard definition format the number of active pixels in a line was chosen to be 720 pixels in both the American and European systems.
Note that the active line period is $52~\mu \mathrm{s}$ in both systems, from which the number of active pixels is $N_{H,a} = T_{\mathrm{H,a}} \cdot f_s = 702$.
Hence, the 720 pixels contains a small interval from the blanking time as well, due to the uncertainty in the position of the actual analog video signal, distortions and smears near the edges, originating from analog processing.
The actual digital video data is taken as 704 pixels from the center of the nominal 720 pixels.
Obviously, the number of the vertical total and active pixels are simply given by the number of total and active scan lines.

The spatial resolution/pixel number of the SD formats is illustrated in \ref{Fig:SD_format}.
The two formats are named after the number of the active lines, resulting the the two SD formats being \textbf{480i} and \textbf{576i}, with ,,i'' referring to the fact that for both formats only interlaced scan is defined.

As it has been already discussed, the aspect ratio of the reproduced SD images should have the aspect ratio of 4:3, which is termed as the \textbf{display aspect ratio (DAR)}.
However, the ratio of the number of the horizontal and vertical pixel numbers---termed as the \textbf{storage aspect ratio (SAR)} does not coincide this ratio in neither formats.
The target display aspect ratio, therefore, can be achieved only by applying non-square pixels on the display side, described by the \textbf{pixel aspect ratio (PAR)}, defined as the ratio of the horizontal and vertical pixel size.
Therefore, format 480i has a pixel aspect ratio of 10:11, and 576i has the PAR of 12:11 with the DAR of 4:3 for both cases.
In contrary, computer displays are employing squared pixels with the PAR of 1:1, and the standard VGA resolution being 640x480 pixels.

\begin{table}[h!]
\caption{Spatial and temporal parameters of SD video formats}
\renewcommand*{\arraystretch}{2}
\label{tab:SD_formats}
\begin{center}
    \begin{tabular}[h!]{ @{}c | | l | l | l @{} }%\toprule
				         &   480i	   &    576i \\ \hline
    active pixel number: &  704 x 480  &   704 x 576   \\
    total pixel number:  &  858 x 525  &  864 x 625 \\
    display aspect ratio:&  4:3 &  4:3 \\
    pixel aspect ratio   &  10:11  & 12:11  \\
    field rate:          &  $59.94~\mathrm{Hz}$ &   $50~\mathrm{Hz}$ \\
    frame rate:          &   $29.97~\mathrm{Hz}$ &  $25~\mathrm{Hz}$ \\
    \end{tabular}
\end{center}
\end{table}

As a short summary of the foregoing the properties of the SD formats are the following:
\begin{itemize}
\item The chromaticity of the primaries and the gamut of the device RGB color space is illustrated in Figure \ref{Fig:SD_gamut} (a).
The white point of the colors space is D65 white.
The luma is calculated from the nonlinear RGB components as 
\footnote{
It is noted here that the above coefficients---unmathematically---do not coincide with the second row of the $XYZ \rightarrow RGB$ transformation matrix (which can be calculated from the primaries and the white point).
This means that strictly speaking the $Y$ component---calculated from the RGB values with the above coefficients---does not equal to the relative luminance.
Instead, for the sake of simplicity the luma coefficients of the NTSC system were used.
These mathematical inconsistencies are usual in videotechnologies.}
\begin{equation}
Y' = 0.299 R' + 0.587 G' + 0.112 B'.
\end{equation}
\item In order to achieve perceptual quantization the source RGB signals are pre-distorted with the opto-electronic transfer function, given by
%
\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.4 \columnwidth ]{Figures/sd_gamut.png}
	\small
	\put(0,0){(a)}
	\end{overpic}
	\hspace{2mm}
	\begin{overpic}[width = 0.55 \columnwidth ]{Figures/sd_OETF.png}
	\small
	\put(0,0){(b)}
	\end{overpic}
	\caption{Gamut (a) and OETF (b) of the ITU-601 SD format}
	\label{Fig:SD_gamut}
\end{figure}
\begin{equation}
E = 
\begin{cases}
4.500 L, \hspace{20mm} \mathrm{ha}\, L < 0.018 \\
1.099 L^{0.45} - 0.099, \hspace{3mm} \mathrm{ha}\, L \geq 0.018,
\end{cases}
\end{equation}
where $L \in \{ R, G, B \}$.
The entire curve can be approximated by $L^{0.5}$.
\item The original SD display aspect ratio was 4:3.
After the introduction of the HD format also the SD format was extended with the aspect ratio of 16:9.
\item SD format exclusively supports interlaced scanning.
\item ITU-601 originally only allowed the chroma subsampling scheme 4:2:2.
Later it was extended with the scheme 4:2:0 for consumer applications.
\item The SD format applies the sampling frequency of $f_s = 13.5~\mathrm{MHz}$. 
The format strictly prescribes the antialiasing low-pass filters, bandlimiting the luma signal to $5.75~\mathrm{MHz}$ as the upper frequency limit and $6.75~\mathrm{MHz}$ as the lower limit of the stopband.
The chroma is sampled with halved sampling frequency, and prefiltered with corresponding antialiasing filters.
\item The sampled luma and chroma sampled are quantized with 8 (for consumer electronics and broadcasting applications) or 10 bits (in studio applications) of bit depths.
\end{itemize}

\subsection{The HD format}

The starting point for the introduction of the analog video formats, leading directly to SD digital format was to cover approximately about $10^{\circ}$ of the central vision from the viewer's field of view.
Obviously, this requirement does not directly define the display size, or the spatial resolution.
Instead at a given resolution and display size the optimal viewing distance can be derived.
In the following, first this optimal viewing distance is investigated, highlighting the basic motivation behind the introduction of the HD and UHD formats.

\subsubsection*{The optimal viewing distance}

\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.67 \columnwidth ]{Figures/hd_pixel_angle_mod.png}
	\small
	\end{overpic}
	\caption{Geometry for deriving the optimal viewing distance}
	\label{Fig:optimal_vd}
\end{figure}

Generally speaking the goal of pixel based image reproduction is to ensure that the light rays, arriving from adjacent pixels include an angle below the spatial resolution of the human vision.
Once it is achieved it is inherently ensured that the pixel structure of the image is not visible, and allows RGB based color reproduction, since instead of perceiving the individual RGB primaries, only the mixture of the primaries is perceived.
In the foregoing it has been discussed that the visual acuity of human vision is $\frac{1}{60}^{\circ}$ (at least for luminance, for colors the resolution is significantly lower), from which for a given pixel size the minimal viewing distance can be derived.
In practice instead of the pixel size, the dimensions and the horizontal and vertical resolution of displays are given, hence it is useful to express the minimal viewing distance as the function of these quantities.

In the following, the geometry depicted in Figure \ref{Fig:optimal_vd} is investigated in case of a display with given height $H$ and number of active lines $N_V$, with the display located at a distance $D$ from the viewer.
The vertical pixel size is then $\frac{H}{N_V}$.

The perceived angle between the adjacent pixels ate the observer position is then given as 
\begin{equation}
\tan \frac{\Phi}{2} = \frac{H}{2 N_V D}.
\end{equation}
For the sake of simplicity the small argument approximation of the tangent function can be applied, i.e. $\tan x \approx x$, ha $x \ll 1$, leading to
\begin{equation}
\Phi = \frac{H}{N_V D} \hspace{3mm} \rightarrow \hspace{3mm} D = \frac{H}{N_V \Phi}.
\end{equation}
By substituting the visual activity of the HVS ($\frac{1}{60}\cdot \frac{\pi}{180}~\mathrm{rad} = 2.9 \cdot 10^{-4}$) for a display with given vertical resolution the optimal (minimal) viewing distance is given by
\begin{equation}
D = H \frac{1}{N_V \,  2.9 \cdot 10^{-4}}.
\end{equation}
This is the so-called \textbf{Lechner distance}, formulating the optimal viewing distance, taken into consideration during the deigning of a display with given size and resolution.

\begin{table}[h!]
\caption{Optimal viewing distance of common SD and HD formats and the covered observer field of view}
\renewcommand*{\arraystretch}{2.25}
\label{tab:viewing_dist}
\begin{center}
    \begin{tabular}[h!]{ @{}c | | l | l | l @{} }%\toprule
				         &   SD, 480i & SD, 576i &	 HDTV \\ \hline
    Active lines:	 &     480 	  		   &   576   				&	 1080\\
    Viewing distance:   &  7 x height &  6 x height & 3 x height\\
    Viewing distance:       &  4.25 x diameter &  3.6 x diameter & 1.5 x diameter\\
    Horizontal field of view &  $\approx 11^{\circ}$ &    $\approx 13^{\circ}$ & $\approx 32^{\circ}$ \\
    \end{tabular}
\end{center}
\end{table}

In case that also the display aspect ratio (denoted by $a_r$) is given (for SD 4:3 and for HD 16:9) the Lechner distance can be expressed as the function of the horizontal dimension (for the sake of simplicity assuming square pixels):
\begin{equation}
D = \frac{W}{a_r} \frac{1}{N_V \,2.9 \cdot 10^{-4}},
\end{equation}
where $W$ is the horizontal dimension (width) of the display.
Furthermore, if the display is observed from the optimal viewing distance, the horizontal field of view angle can be expressed, included by the display:
\begin{equation}
\tan \frac{\Phi_H}{2} = \frac{W}{2 D} \hspace{1cm} \rightarrow \hspace{1cm} D = \frac{W}{2 \tan \frac{\Phi_H}{2}}, 
\end{equation}
and the field of view is written as
\begin{equation}
\Phi_H = 2\arctan \left( \frac{a_r \, N_V \, 2.9\cdot 10^{-4}}{2} \right).
\end{equation}

The evaluation of these results for the discussed SD formats and the upcoming HD formats is summarized in Table \ref{tab:viewing_dist}.
As a result it is obtained that displays with SD resolution should be observed from a distance 6-7 times the height of the screen.
In this case, it is verified that the display covers about 10-13 degrees from the observer's field of view horizontally.

The table already foreshadows the main motivation behind the introduction of HD video format: increasing the perceived reality of the reproduced scene, by filling an increased field of view with video content, compared to SDTV. Therefore, the basic goal was not to squeeze six times the number of pixels into the same visual angle opposed to the popular misbelief.
Instead the angular subtense of a single pixel should be maintained, and the entire image shoud occupy a much larger area of the viewer's visual field.

\subsubsection*{Short HD history}

Although today the term high definition format is associated with digital video, even in the era of early analog TV system increased resolution, high definition initiations existed.
Years before the introduction of color television, in 1949 France started analog monochromatic transmission with a high resolution standard at 819 lines (with 737 active lines), a system that should have been high definition even by today's standards, discontinued only in 1983. 
In 1958, the Soviet Union developed the Transfomator, the first high-resolution television system capable of producing an image composed of 1125 lines of resolution aimed at providing teleconferencing for military command. It was a research project and the system was never deployed by either the military or consumer broadcasting.

In 1979, the Japanese public broadcaster NHK (Japan Broadcasting Corporation) developed consumer high definition television with 1125 scan lines and a 5:3 display aspect ratio.
The system, known as Hi-Vision or MUSE required about twice the bandwidth of the existing NTSC system but provided about four times the resolution, applied for analog regular HD broadcasting beginning in 1994.
The limited standardization of analog HDTV in the 1990 did not lead to global HDTV adoption as technical and economic constraints did not permit HDTV to use bandwidths greater than normal television.

The introduction of the HD format was finally motivated by the emerging of digital compression methods (mainly of MPEG-1 and MPEG-2).
The HD format was codified in the \href{https://www.itu.int/dms_pubrec/itu-r/rec/bt/R-REC-BT.709-6-201506-I!!PDF-E.pdf}{ITU-709} (Rec. 709) standard, published in 1990.

\subsubsection*{HD parameters}

The ITU-709 recommendation prescribed the following properties for HD video format:
\begin{itemize}
\item \textbf{Aspect ratio:} The first standardized parameter for the new video format was its aspect ration, being chosen to 16:9.
The choice is not obvious, since at the time of the standardization process no video content was captured with this aspect ratio: 
TV movies were shot with the aspect ratio of SD format (4:3), while movie films used widescreen formats (most commonly the 1.85:1 and 2.2:1 widescreen, or 2.35:1 anamorphic format).
It has been found that rectangles with the side ratios of the above popular aspect ratios and with equal areas exactly fit within an outer rectangle with the aspect ratio of 16:9.
Furthermore, the intersection of all these rectangles is an inner rectangle with the aspect ratio of 16:9.
Therefore, the aspect ratio of 16:9 ensured the compatibility with most of the then-existing formats.
The geometry is shown in Figure \ref{Fig:kerns_powers}.
%
\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.9 \columnwidth ]{Figures/KernsPowers.png}
	\small
	\end{overpic}
	\caption{The 16:9 aspect ratio as the outer and inner rectangle of rectangles with common aspect ratios}
	\label{Fig:kerns_powers}
\end{figure}
%
\item \textbf{Raster scan, field and frame rate:}
In the HD system besides interlaced scanning the possibility of progressive scan was introduced.
As the legacy of the SD system, numerous field rate and field rates are specified by the format, being $24~\mathrm{Hz}$, $25~\mathrm{Hz}$, $30~\mathrm{Hz}$, $50~\mathrm{Hz}$ and $60~\mathrm{Hz}$ field/frame rates, along with fractional rates, having the above values multiplied by $\frac{1000}{1001}$.


\item \textbf{Sampling frequency:}
The HD sampling frequency can be derived from the SD sampling rate:
One of the main goals of the HD format was to double both the horizontal ($\times 2$) and vertical ($\times 2$) spatial resolution, along with the aspect ratio changed to 16:9 ($4 : 3 \times 4/3$), which the total pixel number being at least $2\times 2 \times \frac{4}{3} = 5.33$ times that of the SD format.
In order to ensure orthogonal sampling (only full pixels in a line) for most field and frame rates the optimal choice for the sampling frequency was $5.5 \cdot 13.5 = 74.25~\mathrm{MHz}$ and the fractional sampling frequency $\frac{1000}{1001} \cdot 74.25~\mathrm{MHz}$ for fractional field/frame rates.
In case of progressive scanning for frame rates $50-60~\mathrm{Hz}$ the data rate is double compared to the interlaced case, therefore, a doubled sampling frequency of $fs = 148.5~\mathrm{MHz}$ is required.
%TODO : kibogar√°szni Kov√°csI jegyzet√©b≈ël a mintav√©teli frek. megv√°laszt√°s√°t (VidStTech 01.pdf, 46.o)

\item \textbf{Spatial resolution:} 
After a lengthy debate \footnote{The first version of the standard specified 1035 active lines, which was later withdrawn.} the number of active line has been codified to 1080 and the total number of lines to 1125, including the vertical blanking with both progressive and interlaced scan modes (this raster format was also codified in SMPTE 274M).
The horizontal number of active pixels has been chosen to a fixed number of 1920 regardless of the frame/field rate, resulting in the active resolution of $1920 \times 1080$.
Therefore, the HD formats with different field and frame rates only differ in the number of total horizontal number of pixels (i.e. in the length of the horizontal blanking time).
%
\begin{table}[h!]
\caption{Sampling frequency, total number of lines and columns and active resolution of commonly used HD formats.
The total number of pixels in a line can be calculated according to $N_\mathrm{H} = f_s \times \frac{f_{\mathrm{V}}}{N_\mathrm{V}}$, with $f_{\mathrm{V}}$ being the frame rate.}
\renewcommand*{\arraystretch}{2.25}
\label{tab:viewing_dist}
\begin{center}
    \begin{tabular}[h!]{ @{}c | l | l | l | l | l @{} }%\toprule
		Format       &   $f_s \, [\mathrm{MHz}]$ 				& $N_\mathrm{H}$ & $N_\mathrm{V}$ & Active resolution \\ \hline
		$720p50$     &   $74.25~\mathrm{MHz}$    				& 1980     &  750  & $1280 \times 720$ \\
		$720p59.94$  &$74.25\cdot\frac{1000}{1001}~\mathrm{MHz}$& 1650     &  750  & $1280 \times 720$ \\
		$1080i25$ 	 &   $74.25~\mathrm{MHz}$    				& 2640     & 1125  & $1920 \times 1080$ \\
		$1080i30$  	 &   $74.25~\mathrm{MHz}$    				& 2200     & 1125  & $1920 \times 1080$ \\
		$1080p50$ 	 &   $148.5~\mathrm{MHz}$    		    	& 2640     & 1125  & $1920 \times 1080$ \\
		$1080p59.94$ &$148.5\cdot\frac{1000}{1001}~\mathrm{MHz}$& 2200     & 1125  & $1920 \times 1080$ 
        \end{tabular}
\end{center}
\end{table}
\vspace{3mm}
The different HD formats are denoted using the following convention:
\begin{itemize}
\item Active resolution in pixels, denoting often only the vertical resolution
\item Scanning mode: $p$ for progressive and $i$ for interlaced
\item frame rate.
For interlaced video often instead of frame frate---incorrectly---field rate is marked.
\end{itemize}
As an example: $1080i25$ denotes interlaced video with 1080 active lines, and the frame rate of $25~\mathrm{Hz}$ (i.e. field rate is $50~\mathrm{Hz}$).
\begin{figure}[]
	\centering
	\begin{overpic}[width = 1 \columnwidth ]{Figures/HD_format.png}
	\small
	\end{overpic}
	\caption{Az 1080 soros √©s 720 soros HD form√°tum szeml√©ltet√©se}
	\label{Fig:HD_formats}
\end{figure}

Due to the large data rate of progressive HD formats the ITU-709 has been extended with a lower spatial resolution format, containing 720 active lines and 1280 active pixels in a line, with exclusively progressive scanning mode.
\footnote{
As already discussed, the basic goal of 1080 lined format was to double the number of scan lines.
The line number of the 720p format---as an intermediate format between SD and HD---applies $\frac{3}{2} \cdot 480 = 720$ scan lines, with the horizontal number of pixels obtained from the aspect ratio of 16:9}.
It is denoted by: \textbf{720p}.
Two examples for the two basic HD formats can be seen in \ref{Fig:HD_formats}.
\item The primaries of the HD format coincide with that of the ITU-601 SD format, resulting in the same gamut.
The luma (and the relative luminance) is calculated as
\begin{equation}
Y' = 0.2126 R' + 0.7152 G' + 0.0722B'.
\end{equation}
\begin{figure}[]
	\centering
	\begin{overpic}[width = 1\columnwidth ]{Figures/hd_line.png}
	\end{overpic} 
	\caption{Structure of one line of the 1080 lined HD format.}
	\label{Fig:hd_line}
\end{figure}
Opposed to the SD formats, in this case the luma coefficients are mathematically correct, obtained from the relative luminance coefficients of the chosen primaries and its white point, i.e. the coefficients correspond to the second row of the $RGB \hspace{3mm} \rightarrow \hspace{3mm} XYZ$ transformation matrix.
\item The opto-electronic transfer function coincides with the SD's OETF:
\begin{equation}
E = 
\begin{cases}
4.500 L, \hspace{20mm} \mathrm{ha}\, L < 0.018 \\
1.099 L^{0.45} - 0.099, \hspace{3mm} \mathrm{ha}\, L \geq 0.018,
\end{cases}
\end{equation}
where $L \in \{ R, G, B \}$.
\item The bit depth is 8 bits for consumer and 10 bits for studio applications.
\item The studio standard codifies the chroma subsampling scheme of 4:2:2.
\end{itemize}
The structure of the resulting standardized HD video signal is the same as the SD video signal, discussed in the foregoing, illustrated in Figure \ref{Fig:hd_line}.
The sole difference is the application of tri-state sync pulses, with the physical dynamic range usually being $0, \pm300~\mathrm{mV}$.

\subsubsection*{Uncompressed data rate of HD formats}

In the following the uncompressed data rate of different video formats is discussed.
With denoting the active and total pixel dimensions the notations showed in Figure \ref{Fig:size} the total data rate can be calculated as
\begin{equation}
B\!R_T = \underbrace{N_{\mathrm{H}} \cdot N_{\mathrm{V}} \cdot f_{\mathrm{V}} \cdot n_{\mathrm{bit}}}_{\text{bitrate per sample}} \cdot n_{\mathrm{CS}},
\end{equation}
with denoting $f_{V}$ the frame rate, $n_{\mathrm{bit}}$ the bit depth and $n_{\mathrm{CS}}$ the number of components, depending on the chroma subsampling scheme applied.
The value of the latter is $n_{\mathrm{CS}} = 3$ for 4:4:4, $n_{\mathrm{CS}} = 2$ for 4:2:2 and $n_{\mathrm{CS}} = 1.5$ for 4:2:0 schemes.

Similarly the active data rate is calculated as
\begin{equation}
B\!R_A = N_{\mathrm{H,A}} \cdot N_{\mathrm{V,A}} \cdot f_f \cdot n_{\mathrm{bit}} \cdot n_{\mathrm{CS}}
\end{equation}.

The active and total bit rates of several frequently used video formats are summarized in Table \ref{tab:bitrate}\footnote{
The vertical blanking interval of UHD format is \href{http://programmersought.com/article/7908103552/}{fixed} to 90 lines, with the horizontal blanking depending on the frame rate of the video.
For a video with the frame rate of $60~\mathrm{Hz}$ the horizontal blanking interval is 560 samples.
}.
\begin{figure}[]
\captionsetup{singlelinecheck=off}
	\centering
	\begin{minipage}[c]{0.4\textwidth}
	\begin{overpic}[width = 1\columnwidth ]{Figures/size.png}
	\end{overpic}   \end{minipage}\hfill
		\begin{minipage}[c]{0.55\textwidth}
	\caption[]{Notation-convention for calculating the data rate of video
	\begin{itemize}
	\item $N_{\mathrm{H}}$: Total pixel number/line
	\item $N_{\mathrm{H,A}}$: Active pixel number/line
	\item $N_\mathrm{V}$: Total number of lines/frame
	\item $N_\mathrm{V,A}$: Number of active lines/frame
	\end{itemize}}
	\label{Fig:size}  \end{minipage}
\end{figure}
%
\begin{table}[h!]
\caption{The total and active bitrate of frequently used video formats}
\renewcommand*{\arraystretch}{2.25}
\label{tab:bitratet}
\begin{center}
    \begin{tabular}[h!]{ @{}c | l | l | l | l | l @{} }%\toprule
\thead{Format} & \thead{Sampling \\ frequency} &    \thead{Total bitrate \\ 4:2:2} & \thead{Active bitrate\\ 4:2:2} & \thead{Active  bitrate\\ 4:4:4} \\ \hline
$576p50$     &   $13.5~\mathrm{MHz}$        & $0.54~\mathrm{Gbit/s}$  & $0.41~\mathrm{Gbit/s}$ & $0.62~\mathrm{Gbit/s}$ \\
$720p60$     &   $74.25~\mathrm{MHz}$    	& $1.49~\mathrm{Gbit/s}$  & $1.11~\mathrm{Gbit/s}$ & $1.67~\mathrm{Gbit/s}$ \\
$1080i30$ 	 &   $74.25~\mathrm{MHz}$    	& $1.49~\mathrm{Gbit/s}$  & $1.24~\mathrm{Gbit/s}$ & $1.86~\mathrm{Gbit/s}$ \\
$1080p60$ 	 &   $148.5~\mathrm{MHz}$    	& $2.97~\mathrm{Gbit/s}$  & $2.49~\mathrm{Gbit/s}$ & $3.73~\mathrm{Gbit/s}$ \\
$2160p60$ 	 &   $297~\mathrm{MHz}$         &  $11.88~\mathrm{Gbit/s}$& $9.96~\mathrm{Gbit/s}$ & $14.93~\mathrm{Gbit/s}$
\end{tabular}
\end{center}
\end{table}
%
The uncompressed bit rate approximately equals for $720p$ and $1080i$ formats.
An advantage of the progressive format is it can be more efficiently compressed than interlaced video.
On the other hand interlaced format ensures high vertical resolution for still and slowly moving video content, although with the resolution degrading for moving reproduced objects.
Therefore, broadcasting operators with sport content in their main profile traditionally chose $720p50/60$ format, while operators, broadcasting mainly news and movies usually apply $1080i$ video format.

%TODO 8b/10b codin
% Fischer Digital Video and Audio broadcasting technology 227.o

%TODO HD ready
%TODO Gaumt coverage percentage, Surface colors
%TODO In typical production practice the encoding function of image sources is adjusted so that the final picture has the desired aesthetic look, as viewed on a reference monitor with a gamma of 2.4 (per ITU-R BT.1886) in a dim reference viewing environment (per ITU-R BT.2035).[10][11][12]
%TODO Rec. 2100, a standard for HDTV and UHDTV with high dynamic range

\subsection{The UHD format}

The original intention behind the introduction of HD format was to enhance the visual experience by increasing the listener's visual angle filled with video content.
The ultra high definition format aims at the further improvement of the reproduction quality by applying even larger display sizes---covering an even larger part of the field of view---and by increasing the displayed image quality.

Similarly to the HD format, the first notable initiation of UHD technology is connected to the Japanese NHK, capturing video data at the resolution of $7680 \times 4096$ by using an array of 16 HDTV recorders and four CCD sensors with the resolution $3840 \times 2048$, as early as 2003.
The first UHD standard was published in 2007 (SMPTE 2036), while the currently accepted UHD codification was introduced in 2012, entitled the \textbf{ITU-R BT. 2020}.
The standard specifies two UHD formats, the 4k with its spatial resolution being the double of the 1080p format both horizontally and vertically (meaning 4 times larger total pixel size), and the 8k, with a further  doubled resolution, compared to 4k.

\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.85 \columnwidth ]{Figures/fov_formats.png}
	\small
	\end{overpic}
	\caption{Visual angle ensured by SD, HD and UHD formats, with the screen being watched from the optimal viewing distance.}
	\label{Fig:fov_formats}
\end{figure}

Theoretically, the goal of the 4k and 8k formats was to fill the visual angle of approximately $58^{\circ}$ and $96^{\circ}$ with content, respectively.
The visual angle of the different SD, HD and UHD formats are compared in Figure \ref{Fig:fov_formats}.

In order to ensure high quality video reproduction over a large visual angle the ITU-2020 improved the reproduction parameters in numerous aspect compared to HD:
\begin{itemize}
\item \textbf{Spatial resolution:} 
The standard specifies two resolution types: $3840 \times 2160$ termed as 4k and $7680 \times 4320$ as 8k resolutions.
Both 4k and 8k employs squared pixels, i.e. both the display and storage aspect ratios are 16:9.
%
\item \textbf{Scanning type:}
Unlike HD, ITU-2020 exclusively allows progressive scanning mode (i.e. the $p/i$ designation is no longer used).

\item \textbf{Frame rate:}
With the increased visual angle the UHD content already fills the peripheral vision of the observer with content.
Since the peripheral vision is dominated by rods with a much quicker response time than the cones of the central vision, thus, in order to ensure continuous motion and avoid flickering significantly higher frame rates are supported than the HD frame rates.
The standard allows the frame rates of $120, 119.88, 100, 60, 59.94, 50, 30, 29.97, 25, 24, 23.976~\mathrm{Hz}$.
\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.75 \columnwidth ]{Figures/uhd_gamut.png}
	\small
	\end{overpic}
	\caption{Gamut of the ITU-2020 UHD color space compared with the gamut of SD and HD color representations.}
	\label{Fig:UHD_gamut}
\end{figure}

\item \textbf{Color space:} 
For the first time since the introduction of NTSC the ITU-2020 UHD standard applies new RGB primaries for color representation for the sake of an enlarged gamut.
The resulting gamut is shown in Figure \ref{Fig:UHD_gamut}: 
As the figure verifies it, the UHD color space applies spectral colors for the RGB primaries, described by the wavelengths of $\lambda_R = 630~\mathrm{nm}$, $\lambda_G =532~\mathrm{nm}$ and $\lambda_B =467~\mathrm{nm}$.
\footnote{
Obviously, this does not mean that UHD displays use spectral colors as RGB primaries, instead the color pixels of UHD video content are stored and transmitted in terms of spectral primary colors.
Monitors and TVs display colors by using the actual applied LCD or LED primary colors, first converting the ITU-2020 content into the RGB color space of the display.
The gamut of these color spaces are obviously smaller than the gamut of the UHD standard: as an example, JDI introduced a \href{https://www.displaydaily.com/?view=article&id=62235:jdi-may-have-commercial-problems-but-has-technical-highlights}{studio reference monitor} with the diameter of $14.3''$ in 2018, allowing the reproduction of $97\%$ of the ITU-2020 color space.}.
The ITU-2020 covers the $75.8\% of$ the CIE chromaticity diagram and the entire Pointer's gamut of real surface colors
\footnote{
The Pointer's gamut is the result of the series of measurements, containing the chromaticites (hues) of colors of reflective surfaces, occurring in the natural environment---opposed to the colors that can be produced by emissive surfaces, e.g. neon or colors of LED/LCD light sources.
The \href{https://cinepedia.com/picture/color-gamut/}{Pointer's gamut} is based on 4089 measurement samples, with the database published in 1980.
Since then, the Pointer's gamut is a de facto standard of qualifying \href{https://www.tftcentral.co.uk/articles/pointers_gamut.htm}{color spaces}.}.
The relative luminance (and the luma) can be calculated from the RGB coordinates as 
\begin{equation}
Y = 0.2627 \, R + 0.6780 \, G + 0.0593 \, B.
\label{eq:2020_Y}
\end{equation}
\item \textbf{Bit depth:} 
The increase of the range of the described colors requires increasing the bit depth of representation as well, in order to ensure the same quantization precision.
Since a larger color space increases the difference between colors an increase of 1-bit per sample is needed for Rec. 2020 to equal or exceed the color precision of ITU-709.
Thus, Rec. 2020 defines a bit depth of either 10 bits per sample for consumer or 12 bits per sample for studio applications.
\item \textbf{The opto-electronic transfer function:} 
The OETF of the ITU-2020 coincides with that of the SD and HD standards:
\begin{equation}
E = 
\begin{cases}
4.500 L, \hspace{20mm} \mathrm{ha}\, L < \beta \\
\alpha L^{0.45} - (\alpha - 1 ), \hspace{3mm} \mathrm{ha}\, L \geq \beta,
\end{cases}
\end{equation}
where $\alpha = 1.09929682680944$ and $\beta = 0.018053968510807$.
The only difference is the precision of the coefficients: for 12 bits bit depth the above coefficients should be evaluated with 5 digits precision.
%
\item \textbf{Chroma subsampling:} 
The standard specifies the subsampling schemes of 4:2:0, 4:2:2 and 4:4:4.
In the latter case instead of luma-chroma representation direct $R'G'B'$ representation is allows.
In case of 4:2:0 or 4:2:2 sampling, besides \ycbcr representation the so-called \textbf{contant luminance mode} is supported, resulting in the $Y C_{\mathrm{bc}} C_{\mathrm{rc}}$ components.
This constant luminance mode may be used when the top priority is the most accurate retention of luminance information.
The luma component in $Y C_{\mathrm{bc}} C_{\mathrm{rc}}$ is calculated using the same coefficient values as for \ycbcr, but it is calculated from linear RGB and then gamma corrected, rather than being calculated from gamma-corrected $R'G'B'$.
As a result $Y'$ in constant luminance mode is mathematically accurately describes the gamma-corrected relative luminance component (therefore, the resulting luma contains no color information and the resulting chroma contains no luminance information).
The prevents artifacts that arise in case of \ycbcr representation due to the subsampling of minor luminance information, present in the chroma components.
\end{itemize}

%TODO \paragraph{Konstans f√©nys≈±r≈±s√©g≈± m√≥d:\\}
\subsection{Digital interfaces}
The most common physical interface for SD, HD and UHD video transmission in video studiotechnologies is the SDI (Serial Digital Interface), and HDMI (High-Definition Multimedia Interface) in consumer applications.

The bit rates of most common video formats were summarized in Table \ref{tab:bitratet}.
As a comparison, the maximal digital bandwidth of the different HDMI interface versions are the following
\begin{itemize}
\item HDMI 1.0-1.2: 4.95 Gbit/s (3.96 Gbit/s effective)\footnote{
Due to undiscussed reasons the HDMI interface applies a so-called 8b/10b channel coding, transmitting 8 bits of data in 10 bit sequences.
Therefore, only the part of $\frac{8}{10}$ of the total bandwith can used for effective data transmission.}
\item HDMI 2.0: 18 Gbit/s (14.4 Gbit/s effective)
\item HDMI 2.1: 48 Gbit/s (38.4 Gbit/s effective)
\end{itemize}
Obviously, in order to find the HDMI version for the transmission of a given video format, the total number of lines and sample per lines have to be taken into consideration, since HDMI signals contains the horizontal and vertical blanking intervals as well.
As discussed earlier: the vertical blanking interval carries multichannel audio streams and other auxiliary data, presented simultaneously with the video data.

It can be concluded that HDMI 1.0 version was created mainly for the transmission of 1080p video format with 4:2:2 chroma subsampling scheme, and the bit depth of 10 or 12 bits (4:4:4 video can be only transmitted with this version represented on 8 bits).
On the other hand, HDMI 2.0 was developed for 4k, and the 2.1 version for 8k video transmission.

\begin{figure}[]
	\centering
	\begin{overpic}[width = 0.75 \columnwidth ]{Figures/optimal-viewing-distance-television-graph-size.png}
	\small
	\end{overpic}
	\caption{Optimal viewing distance as the function of display diameter.}
	\label{Fig:optimal_vd_2}
\end{figure}

\subsection{Optimal choice of display resolution}

As the conclusion of the present chapter the Lechner distance is revisited in order to arrive at the the optimal viewing distance for a given display size and for the optimal display size for a given observer distance.
Besides the Lechner distance, several other recommendations exist for the optimum viewing distance, including manufacturers, retail and THX recommendations.
\begin{itemize}
\item SMPTE 30: is the standardized codification of the Lechner distance, recommending the viewing distance of 1.6 times the diameter in case of a HD display with 1080 lines, resulting in a field of view of $30^{\circ}$.
This recommendation is very popular with the home theater enthusiast community, appearing in books on home theater design,
%
\item The recommendation of manufacturers, retails and several publications suggests the viewing distance of 2.5 times the diameter in case of a HD display, resulting in the field of view of $20^{\circ}$.
%
\item THX recommends that the ,,best seat-to-screen distance'' is one where the view angle approximates $40^{\circ}$, which according to the THX approximates the cinema experience the most.
This is achieved in case of HD format with the viewing distance being 1.2 times the display diameter.
\end{itemize}
Although there are slight discrepancies between these recommendations, they all agree in that for the viewing distance of the HD displays ,,the closer the better''.

The graph of optimal viewing distances can be visualized for the different video formats, as depicted in Figure \ref{Fig:optimal_vd_2}.
At a given display size, of course the viewing distance can be increased, the pixel structure of the display does not become visible.
Thus, at a fixed display size above a given line in the graph the display is applicable.
The graph, therefore, can be divided into regions, indicating the optimal display resolution for a given viewing distance and display size.

\vspace{3mm}
Based on statistics, conducted by Bernard J. Lechner the average domestic TV viewing distance is approximately $2.7~\mathrm{m}$.
At this distance displays above the diameter of 50'' should have the resolution of 1080p, while in order to exploit the advantages and quality of 4k resolution the display should have a diameter of at least 75'' ($\sim 1.9~\mathrm{m}$).
Displays with the diameter of 2 meters are extremely rarely applied in domestic use even today, suggesting that the capabilities of even 4k displays are not completely utilized nowadays.
However, the introduction of consumer 8k displays is already trending, with also experimental 8k broadcasting initiations beginning in the recent years.
As an example, the first dedicated satellite for broadcasting 8k content has been lunched (BSAT-4a), which was planned to broadcast the 2020 summer olympics, which has been however postponed to 2021 due to the outbreak of the COVID-19 pandemic.

%Perif√©rikus l√°t√°s:
%https://www.quora.com/What-is-the-aspect-ratio-of-human-vision

%TODO \subsection{A HDR kiterjeszt√©s}

\vspace{2cm}
\noindent\rule{12cm}{0.4pt}

\subsection*{End-of-Chapter Questions}

\begin{itemize}
\item What were the reasons behind the introduction of the interlaced format?
What is the main idea of interlaced scanning?
%
\item How was the sampling frequency of the SD format chosen?
How was it extended in order to choose the sampling frequency of the HD format?
%
\item Calculate the optimal viewing distance for a 4k (2160p) display with the diameter of 65'' (the aspect ratio is 16:9)!
%
\item List some improvements of the UHD standard compared to the HD format!
%
\item Define the number of total and active resolution of the $2160p60$ format!
The number of inactive lines is 90 and the sampling frequency is $297~\mathrm{MHz}$.
%
\item Define the total bitrate of the video format of the previous example in case of a chroma subsampling scheme of 4:2:2, with 12 bits per sample representation!
Pick the minimal HDMI version which is capable of transmitting the exemplary video stream, if the HDMI transmits 8 bit data in 10 bits sequences (i.e. the effective bandwidth is $\frac{8}{10}$ times the total bandwidth), and the total bandwidth of the HDMI interface versions are
\begin{itemize}
\item HDMI 1.0-1.2: $4.95~\mathrm{Gbit/s}$
\item HDMI 1.3-1.4: $10.2~\mathrm{Gbit/s}$
\item HDMI 2.0-1.2: $18~\mathrm{Gbit/s}$
\item HDMI 2.1: $48~\mathrm{Gbit/s}$
\end{itemize}
\end{itemize}